<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introduction to Statistics | Statistical Foundations</title>
  <meta name="description" content="Chapter 1 Introduction to Statistics | Statistical Foundations" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introduction to Statistics | Statistical Foundations" />
  <meta property="og:type" content="book" />
  
  
  <meta name="github-repo" content="IAA-Faculty/statistical_foundations" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction to Statistics | Statistical Foundations" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="slr.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a style="font-weight:bold, text-align:center" href="https://github.com/IAA-Faculty/statistical_foundations/">Statistical Foundations</a>
<img src="./img/iaaicon.png" alt="IAA"  class="center"</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#authors"><i class="fa fa-check"></i>Authors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro-stat.html"><a href="intro-stat.html"><i class="fa fa-check"></i><b>1</b> Introduction to Statistics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro-stat.html"><a href="intro-stat.html#eda"><i class="fa fa-check"></i><b>1.1</b> Exploratory Data Analysis (EDA)</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="intro-stat.html"><a href="intro-stat.html#vartypes"><i class="fa fa-check"></i><b>1.1.1</b> Types of Variables</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro-stat.html"><a href="intro-stat.html#dist"><i class="fa fa-check"></i><b>1.1.2</b> Distributions</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro-stat.html"><a href="intro-stat.html#normal"><i class="fa fa-check"></i><b>1.1.3</b> The Normal Distribution</a></li>
<li class="chapter" data-level="1.1.4" data-path="intro-stat.html"><a href="intro-stat.html#skew"><i class="fa fa-check"></i><b>1.1.4</b> Skewness</a></li>
<li class="chapter" data-level="1.1.5" data-path="intro-stat.html"><a href="intro-stat.html#kurt"><i class="fa fa-check"></i><b>1.1.5</b> Kurtosis</a></li>
<li class="chapter" data-level="1.1.6" data-path="intro-stat.html"><a href="intro-stat.html#graphdist"><i class="fa fa-check"></i><b>1.1.6</b> Graphical Displays of Distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro-stat.html"><a href="intro-stat.html#pointest"><i class="fa fa-check"></i><b>1.2</b> Point Estimates</a></li>
<li class="chapter" data-level="1.3" data-path="intro-stat.html"><a href="intro-stat.html#ci"><i class="fa fa-check"></i><b>1.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="1.4" data-path="intro-stat.html"><a href="intro-stat.html#hypotest"><i class="fa fa-check"></i><b>1.4</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="intro-stat.html"><a href="intro-stat.html#onesample"><i class="fa fa-check"></i><b>1.4.1</b> One-Sample T-Test</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro-stat.html"><a href="intro-stat.html#two-sample-t-tests"><i class="fa fa-check"></i><b>1.5</b> Two-Sample t-tests</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="intro-stat.html"><a href="intro-stat.html#testnorm"><i class="fa fa-check"></i><b>1.5.1</b> Testing Normality of Groups</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro-stat.html"><a href="intro-stat.html#ftest"><i class="fa fa-check"></i><b>1.5.2</b> Testing Equality of Variances</a></li>
<li class="chapter" data-level="1.5.3" data-path="intro-stat.html"><a href="intro-stat.html#tsttest"><i class="fa fa-check"></i><b>1.5.3</b> Testing Equality of Means</a></li>
<li class="chapter" data-level="1.5.4" data-path="intro-stat.html"><a href="intro-stat.html#wilcoxon"><i class="fa fa-check"></i><b>1.5.4</b> Mann-Whitney-Wilcoxon Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="slr.html"><a href="slr.html"><i class="fa fa-check"></i><b>2</b> Introduction to ANOVA and Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="slr.html"><a href="slr.html#evp"><i class="fa fa-check"></i><b>2.1</b> Prediction vs. Explanation</a></li>
<li class="chapter" data-level="2.2" data-path="slr.html"><a href="slr.html#trainvalidtest"><i class="fa fa-check"></i><b>2.2</b> Honest Assessment</a></li>
<li class="chapter" data-level="2.3" data-path="slr.html"><a href="slr.html#bivariate-eda"><i class="fa fa-check"></i><b>2.3</b> Bivariate EDA</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="slr.html"><a href="slr.html#continuous-continuous-associations"><i class="fa fa-check"></i><b>2.3.1</b> Continuous-Continuous Associations</a></li>
<li class="chapter" data-level="2.3.2" data-path="slr.html"><a href="slr.html#continuous-categorical-associations"><i class="fa fa-check"></i><b>2.3.2</b> Continuous-Categorical Associations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="slr.html"><a href="slr.html#oneway"><i class="fa fa-check"></i><b>2.4</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="slr.html"><a href="slr.html#testing-assumptions"><i class="fa fa-check"></i><b>2.4.1</b> Testing Assumptions</a></li>
<li class="chapter" data-level="2.4.2" data-path="slr.html"><a href="slr.html#kruskal"><i class="fa fa-check"></i><b>2.4.2</b> Kruskal-Wallis</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="slr.html"><a href="slr.html#posthoc"><i class="fa fa-check"></i><b>2.5</b> ANOVA Post-hoc Testing</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="slr.html"><a href="slr.html#tukey"><i class="fa fa-check"></i><b>2.5.1</b> Tukey-Kramer</a></li>
<li class="chapter" data-level="2.5.2" data-path="slr.html"><a href="slr.html#dunnett"><i class="fa fa-check"></i><b>2.5.2</b> Dunnett’s Test</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="slr.html"><a href="slr.html#cor"><i class="fa fa-check"></i><b>2.6</b> Pearson Correlation</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="slr.html"><a href="slr.html#testcor"><i class="fa fa-check"></i><b>2.6.1</b> Statistical Test</a></li>
<li class="chapter" data-level="2.6.2" data-path="slr.html"><a href="slr.html#effect-of-anomalous-observations"><i class="fa fa-check"></i><b>2.6.2</b> Effect of Anomalous Observations</a></li>
<li class="chapter" data-level="2.6.3" data-path="slr.html"><a href="slr.html#the-correlation-matrix"><i class="fa fa-check"></i><b>2.6.3</b> The Correlation Matrix</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="slr.html"><a href="slr.html#simple-linear-regression"><i class="fa fa-check"></i><b>2.7</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="slr.html"><a href="slr.html#slrassumptions"><i class="fa fa-check"></i><b>2.7.1</b> Assumptions of Linear Regression</a></li>
<li class="chapter" data-level="2.7.2" data-path="slr.html"><a href="slr.html#testing-for-association"><i class="fa fa-check"></i><b>2.7.2</b> Testing for Association</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mlr.html"><a href="mlr.html"><i class="fa fa-check"></i><b>3</b> Complex ANOVA and Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="mlr.html"><a href="mlr.html#two-way-anova"><i class="fa fa-check"></i><b>3.1</b> Two-Way ANOVA</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="mlr.html"><a href="mlr.html#exploration"><i class="fa fa-check"></i><b>3.1.1</b> Exploration</a></li>
<li class="chapter" data-level="3.1.2" data-path="mlr.html"><a href="mlr.html#model"><i class="fa fa-check"></i><b>3.1.2</b> Model</a></li>
<li class="chapter" data-level="3.1.3" data-path="mlr.html"><a href="mlr.html#post-hoc-testing"><i class="fa fa-check"></i><b>3.1.3</b> Post-Hoc Testing</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="mlr.html"><a href="mlr.html#two-way-anova-with-interactions"><i class="fa fa-check"></i><b>3.2</b> Two-Way ANOVA with Interactions</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="mlr.html"><a href="mlr.html#post-hoc-testing-1"><i class="fa fa-check"></i><b>3.2.1</b> Post-Hoc Testing</a></li>
<li class="chapter" data-level="3.2.2" data-path="mlr.html"><a href="mlr.html#assumptions"><i class="fa fa-check"></i><b>3.2.2</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mlr.html"><a href="mlr.html#randomized-block-design"><i class="fa fa-check"></i><b>3.3</b> Randomized Block Design</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="mlr.html"><a href="mlr.html#garlic-bulb-weight-example"><i class="fa fa-check"></i><b>3.3.1</b> Garlic Bulb Weight Example</a></li>
<li class="chapter" data-level="3.3.2" data-path="mlr.html"><a href="mlr.html#assumptions-1"><i class="fa fa-check"></i><b>3.3.2</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mlr.html"><a href="mlr.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="mlr.html"><a href="mlr.html#model-structure"><i class="fa fa-check"></i><b>3.4.1</b> Model Structure</a></li>
<li class="chapter" data-level="3.4.2" data-path="mlr.html"><a href="mlr.html#global-local-inference"><i class="fa fa-check"></i><b>3.4.2</b> Global &amp; Local Inference</a></li>
<li class="chapter" data-level="3.4.3" data-path="mlr.html"><a href="mlr.html#assumptions-2"><i class="fa fa-check"></i><b>3.4.3</b> Assumptions</a></li>
<li class="chapter" data-level="3.4.4" data-path="mlr.html"><a href="mlr.html#multiple-coefficients-of-determination"><i class="fa fa-check"></i><b>3.4.4</b> Multiple Coefficients of Determination</a></li>
<li class="chapter" data-level="3.4.5" data-path="mlr.html"><a href="mlr.html#categorical-predictor-variables"><i class="fa fa-check"></i><b>3.4.5</b> Categorical Predictor Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sel.html"><a href="sel.html"><i class="fa fa-check"></i><b>4</b> Model Selection</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sel.html"><a href="sel.html#selection-criteria"><i class="fa fa-check"></i><b>4.1</b> Selection Criteria</a></li>
<li class="chapter" data-level="4.2" data-path="sel.html"><a href="sel.html#stepwise-selection"><i class="fa fa-check"></i><b>4.2</b> Stepwise Selection</a>
<ul>
<li class="chapter" data-level="" data-path="sel.html"><a href="sel.html#forward"><i class="fa fa-check"></i>Forward</a></li>
<li class="chapter" data-level="" data-path="sel.html"><a href="sel.html#backward"><i class="fa fa-check"></i>Backward</a></li>
<li class="chapter" data-level="" data-path="sel.html"><a href="sel.html#stepwise"><i class="fa fa-check"></i>Stepwise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="sel.html"><a href="sel.html#significance-levels"><i class="fa fa-check"></i><b>4.3</b> Significance Levels</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="diag.html"><a href="diag.html"><i class="fa fa-check"></i><b>5</b> Diagnostics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="diag.html"><a href="diag.html#examining-residuals"><i class="fa fa-check"></i><b>5.1</b> Examining Residuals</a></li>
<li class="chapter" data-level="5.2" data-path="diag.html"><a href="diag.html#misspecified-model"><i class="fa fa-check"></i><b>5.2</b> Misspecified Model</a></li>
<li class="chapter" data-level="5.3" data-path="diag.html"><a href="diag.html#constant-variance"><i class="fa fa-check"></i><b>5.3</b> Constant Variance</a></li>
<li class="chapter" data-level="5.4" data-path="diag.html"><a href="diag.html#normality"><i class="fa fa-check"></i><b>5.4</b> Normality</a></li>
<li class="chapter" data-level="5.5" data-path="diag.html"><a href="diag.html#correlated-errors"><i class="fa fa-check"></i><b>5.5</b> Correlated Errors</a></li>
<li class="chapter" data-level="5.6" data-path="diag.html"><a href="diag.html#influential-observations-and-outliers"><i class="fa fa-check"></i><b>5.6</b> Influential Observations and Outliers</a></li>
<li class="chapter" data-level="5.7" data-path="diag.html"><a href="diag.html#multicollinearity"><i class="fa fa-check"></i><b>5.7</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mlr.html"><a href="mlr.html#model"><i class="fa fa-check"></i><b>6</b> Model Building &amp; Scoring for Prediction</a>
<ul>
<li class="chapter" data-level="6.1" data-path="model.html"><a href="model.html"><i class="fa fa-check"></i><b>6.1</b> Regularized Regression</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="model.html"><a href="model.html#penalties-in-models"><i class="fa fa-check"></i><b>6.1.1</b> Penalties in Models</a></li>
<li class="chapter" data-level="6.1.2" data-path="model.html"><a href="model.html#ridge-regression"><i class="fa fa-check"></i><b>6.1.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="6.1.3" data-path="model.html"><a href="model.html#lasso"><i class="fa fa-check"></i><b>6.1.3</b> LASSO</a></li>
<li class="chapter" data-level="6.1.4" data-path="model.html"><a href="model.html#elastic-net"><i class="fa fa-check"></i><b>6.1.4</b> Elastic Net</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="model.html"><a href="model.html#optimizing-penalties"><i class="fa fa-check"></i><b>6.2</b> Optimizing Penalties</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="model.html"><a href="model.html#cross-validation"><i class="fa fa-check"></i><b>6.2.1</b> Cross-Validation</a></li>
<li class="chapter" data-level="6.2.2" data-path="model.html"><a href="model.html#cv-in-regularized-regression"><i class="fa fa-check"></i><b>6.2.2</b> CV in Regularized Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="model.html"><a href="model.html#model-comparisons"><i class="fa fa-check"></i><b>6.3</b> Model Comparisons</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="model.html"><a href="model.html#model-metrics"><i class="fa fa-check"></i><b>6.3.1</b> Model Metrics</a></li>
<li class="chapter" data-level="6.3.2" data-path="model.html"><a href="model.html#test-dataset-comparison"><i class="fa fa-check"></i><b>6.3.2</b> Test Dataset Comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cat.html"><a href="cat.html"><i class="fa fa-check"></i><b>7</b> Categorical Data Analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cat.html"><a href="cat.html#describing-categorical-data"><i class="fa fa-check"></i><b>7.1</b> Describing Categorical Data</a></li>
<li class="chapter" data-level="7.2" data-path="cat.html"><a href="cat.html#tests-of-association"><i class="fa fa-check"></i><b>7.2</b> Tests of Association</a></li>
<li class="chapter" data-level="7.3" data-path="cat.html"><a href="cat.html#measures-of-association"><i class="fa fa-check"></i><b>7.3</b> Measures of Association</a></li>
<li class="chapter" data-level="7.4" data-path="cat.html"><a href="cat.html#introduction-to-logistic-regression"><i class="fa fa-check"></i><b>7.4</b> Introduction to Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="cat.html"><a href="cat.html#linear-probability-model"><i class="fa fa-check"></i><b>7.4.1</b> Linear Probability Model</a></li>
<li class="chapter" data-level="7.4.2" data-path="cat.html"><a href="cat.html#binary-logistic-regression"><i class="fa fa-check"></i><b>7.4.2</b> Binary Logistic Regression</a></li>
<li class="chapter" data-level="7.4.3" data-path="cat.html"><a href="cat.html#adding-categorical-variables"><i class="fa fa-check"></i><b>7.4.3</b> Adding Categorical Variables</a></li>
<li class="chapter" data-level="7.4.4" data-path="cat.html"><a href="cat.html#model-assessment"><i class="fa fa-check"></i><b>7.4.4</b> Model Assessment</a></li>
<li class="chapter" data-level="7.4.5" data-path="cat.html"><a href="cat.html#variable-selection-and-regularized-regression"><i class="fa fa-check"></i><b>7.4.5</b> Variable Selection and Regularized Regression</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Foundations</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro-stat" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> Introduction to Statistics<a href="intro-stat.html#intro-stat" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The following packages will be used in this textbook. Below we install and add the packages to our libraries so that any version issues can be dealt with at the beginning of the course. Sometimes packages require that you update to the latest version of R; if you see an error that indicates that situation, download the latest version of R from <a href="https://cran.r-project.org">CRAN</a> and install it.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="intro-stat.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;AmesHousing&#39;</span>)</span>
<span id="cb1-2"><a href="intro-stat.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;tidyverse&#39;</span>)</span>
<span id="cb1-3"><a href="intro-stat.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;car&#39;</span>)</span>
<span id="cb1-4"><a href="intro-stat.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;DescTools&#39;</span>)</span>
<span id="cb1-5"><a href="intro-stat.html#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;corrplot&#39;</span>)</span>
<span id="cb1-6"><a href="intro-stat.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;mosaic&#39;</span>)</span>
<span id="cb1-7"><a href="intro-stat.html#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;modelr&#39;</span>)</span>
<span id="cb1-8"><a href="intro-stat.html#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;plotly&#39;</span>)</span>
<span id="cb1-9"><a href="intro-stat.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;ggplot2&#39;</span>)</span>
<span id="cb1-10"><a href="intro-stat.html#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;Hmisc&#39;</span>)</span>
<span id="cb1-11"><a href="intro-stat.html#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;onehot&#39;</span>)</span>
<span id="cb1-12"><a href="intro-stat.html#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;jmuOutlier&#39;</span>)</span>
<span id="cb1-13"><a href="intro-stat.html#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;leaps&#39;</span>)</span>
<span id="cb1-14"><a href="intro-stat.html#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;glmnet&#39;</span>)</span>
<span id="cb1-15"><a href="intro-stat.html#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;nortest&#39;</span>)</span>
<span id="cb1-16"><a href="intro-stat.html#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;lmtest&#39;</span>)</span>
<span id="cb1-17"><a href="intro-stat.html#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;InformationValue&#39;</span>)</span>
<span id="cb1-18"><a href="intro-stat.html#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;gmodels&#39;</span>)</span>
<span id="cb1-19"><a href="intro-stat.html#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;vcdExtra&#39;</span>)</span>
<span id="cb1-20"><a href="intro-stat.html#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;TSA&#39;</span>)</span>
<span id="cb1-21"><a href="intro-stat.html#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;carData&#39;</span>)</span>
<span id="cb1-22"><a href="intro-stat.html#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;epiDisplay&#39;</span>)</span>
<span id="cb1-23"><a href="intro-stat.html#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;gridExtra&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="intro-stat.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AmesHousing)</span>
<span id="cb2-2"><a href="intro-stat.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2-3"><a href="intro-stat.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb2-4"><a href="intro-stat.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DescTools)</span>
<span id="cb2-5"><a href="intro-stat.html#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span>
<span id="cb2-6"><a href="intro-stat.html#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mosaic)</span>
<span id="cb2-7"><a href="intro-stat.html#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelr)</span>
<span id="cb2-8"><a href="intro-stat.html#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb2-9"><a href="intro-stat.html#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb2-10"><a href="intro-stat.html#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb2-11"><a href="intro-stat.html#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(onehot)</span>
<span id="cb2-12"><a href="intro-stat.html#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jmuOutlier)</span>
<span id="cb2-13"><a href="intro-stat.html#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb2-14"><a href="intro-stat.html#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb2-15"><a href="intro-stat.html#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nortest)</span>
<span id="cb2-16"><a href="intro-stat.html#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb2-17"><a href="intro-stat.html#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(InformationValue)</span>
<span id="cb2-18"><a href="intro-stat.html#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gmodels)</span>
<span id="cb2-19"><a href="intro-stat.html#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vcdExtra)</span>
<span id="cb2-20"><a href="intro-stat.html#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(TSA)</span>
<span id="cb2-21"><a href="intro-stat.html#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(carData)</span>
<span id="cb2-22"><a href="intro-stat.html#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(epiDisplay)</span>
<span id="cb2-23"><a href="intro-stat.html#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span></code></pre></div>
<p>This first chapter will review some basic statistical concepts that we assume the reader has seen previously. We will demonstrate how to implement these concepts in R along the way.</p>
<div id="eda" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Exploratory Data Analysis (EDA)<a href="intro-stat.html#eda" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- <script> -->
<!-- var acc = document.getElementsByClassName("accordion"); -->
<!-- var i; -->
<!-- for (i = 0; i < acc.length; i++) { -->
<!--   acc[i].addEventListener("click", function() { -->
<!--     this.classList.toggle("active"); -->
<!--     var panel = this.nextElementSibling; -->
<!--     if (panel.style.display === "block") { -->
<!--       panel.style.display = "none"; -->
<!--     } else { -->
<!--       panel.style.display = "block"; -->
<!--     } -->
<!--   }); -->
<!-- } -->
<!-- </script> -->
<!-- <button class="accordion">R</button> -->
<!-- <div class="panel"> -->
<!--  <p> `R Code`</p> -->
<!-- </div> -->
<!-- <button class="accordion">SAS</button> -->
<!-- <div class="panel"> -->
<!--   <p>`SAS Code`</p> -->
<!-- </div> -->
<!-- <button class="accordion">Python</button> -->
<!-- <div class="panel"> -->
<!--   <p>`Python Code` </p> -->
<!-- </div> -->
The crucial first step to any data science problem is exploratory data analysis (EDA). Before you attempt to run any models, or jump towards any formal statistical analysis, you must <strong><em>explore your data</em></strong>. Many unexpected frustrations arise when exploratory analysis is overlooked; knowing your data is critical to your ability to make necessary assumptions about it. This preliminary analysis will help inform our decisions for data manipulation, give us a base-level understanding of our variables and the relationships between them, and help determine which statistical analyses might be appropriate for the questions we are trying to answer. Some of the questions we aim to answer through exploratory analysis are:
<ul>
<li>
What kind of variables to you have?
<ul>
<li>
Continuous
<li>
Nominal
<li>
Ordinal
</ul>
<li>
How are the attributes stored?
<ul>
<li>
Strings
<li>
Integers
<li>
Floats/Numeric
<li>
Dates
</ul>
<li>
What do their distributions look like?
<ul>
<li>
Center/Location
<li>
Spread
<li>
Shape
</ul>
<li>
Are there any anomolies?
<ul>
<li>
Outliers
<li>
Leverage points
<li>
Missing values
<li>
Low-frequency categories
</ul>
</ul>
<p>We will maintain an example data set throughout this text to demonstrate the various tools and techniques being discussed. It is a real-estate data set that contains the <code>sale_price</code> and physical attributes of nearly 3,000 homes in Ames, Iowa in the early 2000s. To access this data, we first add the <code>AmesHousing</code> package to our library and create the nicely formatted data with the <code>make_ordinal_ames()</code> function.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="intro-stat.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AmesHousing)</span>
<span id="cb3-2"><a href="intro-stat.html#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="intro-stat.html#cb3-3" aria-hidden="true" tabindex="-1"></a>ames <span class="ot">&lt;-</span> <span class="fu">make_ordinal_ames</span>() </span>
<span id="cb3-4"><a href="intro-stat.html#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(ames)</span></code></pre></div>
<div id="vartypes" class="section level3 hasAnchor" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Types of Variables<a href="intro-stat.html#vartypes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The columns of a data set are referred to by the following <strong>equivalent terms</strong>:</p>
</ul>
<li>
Variables
<li>
Features
<li>
Attributes
<li>
Predictors/Targets
<li>
Factors
<li>
Inputs/Outputs
</ul>
<p>This book may use any of these words interchangeably to refer to a quality or quantity of interest in our data.</p>
<div id="nominal-variables" class="section level4 unnumbered hasAnchor">
<h4>Nominal Variables<a href="intro-stat.html#nominal-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A <strong>nominal</strong> or <strong>categorical variable</strong> is a <em>quality of interest</em> whose values have no logical ordering. Color (“blue”, “red”, “green”…), ethnicity (“African-American”, “Asian”, “Caucasian”,…), and style of house (“ranch”, “two-story”, “duplex”, …) are all examples of nominal attributes. The categories or values that these variables can take on - those words listed in quotes and parenthesis - are called the <strong>levels</strong> of the variable.</p>
<p>In modeling, nominal attributes are commonly transformed into <strong>dummy variables</strong>. Dummy variables are binary columns that indicate the presence or absence of a quality. There is more than one way to create dummy variables, and the treatment will be different depending on what type of model you are using. Linear regression models will use either <strong>reference-level</strong> or <strong>effects coding</strong>, whereas other machine learning models are more likely to use one-hot encoding or a variation thereof.</p>
<p><strong>One-hot encoding</strong></p>
<p>For machine learning applications, it is common to create a binary dummy column for each level of your categorical variable. This is the most intuitive representation of categorical information, answering indicative questions for each level of the variable: <em>“is it blue?”</em>, <em>“is it red?”</em> etc. The table below gives an example of some data, the original nominal variable (color) and the one-hot encoded color information.</p>
<table>
<tr>
<td>
Observation
<td>
Color
<td>
Blue
<td>
Red
<td>
Yellow
<td>
Other
<tr>
<td>
1
<td>
Blue
<td>
1
<td>
0
<td>
0
<td>
0
<tr>
<td>
2
<td>
Yellow
<td>
0
<td>
0
<td>
1
<td>
0
<tr>
<td>
3
<td>
Blue
<td>
1
<td>
0
<td>
0
<td>
0
<tr>
<td>
4
<td>
Red
<td>
0
<td>
1
<td>
0
<td>
0
<tr>
<td>
5
<td>
Red
<td>
0
<td>
1
<td>
0
<td>
0
<tr>
<td>
6
<td>
Blue
<td>
1
<td>
0
<td>
0
<td>
0
<tr>
<td>
7
<td>
Yellow
<td>
0
<td>
0
<td>
1
<td>
0
<tr>
<td>
8
<td>
Other
<td>
0
<td>
0
<td>
0
<td>
1
</table>
<caption>
<span id="tab:onehot">Table 1.1: </span>One-hot dummy variable coding for the categorical attribute <em>color</em>
</caption>
<p>We will demonstrate the creation of this data using some simple random categorical data:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="intro-stat.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">41</span>)</span>
<span id="cb4-2"><a href="intro-stat.html#cb4-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y =</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">2</span>), <span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">1</span>),<span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">0</span>)),</span>
<span id="cb4-3"><a href="intro-stat.html#cb4-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">x1 =</span> <span class="fu">factor</span>(<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>), <span class="at">each =</span> <span class="dv">10</span>)),</span>
<span id="cb4-4"><a href="intro-stat.html#cb4-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">x2 =</span> <span class="fu">factor</span>(<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Z&quot;</span>, <span class="st">&quot;X&quot;</span>, <span class="st">&quot;Y&quot;</span>,<span class="st">&quot;W&quot;</span>,<span class="st">&quot;V&quot;</span>,<span class="st">&quot;U&quot;</span>), <span class="at">each =</span> <span class="dv">5</span>)))</span>
<span id="cb4-5"><a href="intro-stat.html#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(data)</span></code></pre></div>
<pre><code>##             y x1 x2
## 1   1.2056317  A  Z
## 2   2.1972575  A  Z
## 3   3.0017043  A  Z
## 4   3.2888254  A  Z
## 5   2.9057534  A  Z
## 6   2.4936675  A  X
## 7   2.5992858  A  X
## 8   0.4203930  A  X
## 9   3.0006207  A  X
## 10  4.1880077  A  X
## 11 -0.2093244  B  Y
## 12  0.4126881  B  Y
## 13  2.0561206  B  Y
## 14  0.6834151  B  Y
## 15  0.9454590  B  Y
## 16  1.3297513  B  W
## 17  1.6630951  B  W
## 18  1.8783282  B  W
## 19  1.2028743  B  W
## 20  3.2744025  B  W
## 21 -0.8992970  C  V
## 22  2.1394903  C  V
## 23 -1.1659510  C  V
## 24 -0.0471304  C  V
## 25  0.4158763  C  V
## 26  1.7200805  C  U
## 27 -0.7843607  C  U
## 28 -1.3039296  C  U
## 29 -0.4520359  C  U
## 30 -1.7739919  C  U</code></pre>
<p>Unlike reference and effects coding, which are typically specified within the <code>lm()</code> function as we will see in Chapter <a href="slr.html#slr">2</a>, one-hot encoding is most quickly achieved through use of the <code>onehot</code> package in R, which first creates an “encoder” to do the job quickly.</p>
<p>The speed of this function has been tested against both the base R <code>model.matrix()</code> function and the <code>dummyVars()</code> function in the <code>caret</code> package and is <em>substantially</em> faster than either.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="intro-stat.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(onehot)</span>
<span id="cb6-2"><a href="intro-stat.html#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="intro-stat.html#cb6-3" aria-hidden="true" tabindex="-1"></a>encoder  <span class="ot">=</span> <span class="fu">onehot</span>(data)</span>
<span id="cb6-4"><a href="intro-stat.html#cb6-4" aria-hidden="true" tabindex="-1"></a>dummies <span class="ot">=</span> <span class="fu">predict</span>(encoder,data)</span>
<span id="cb6-5"><a href="intro-stat.html#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dummies)</span></code></pre></div>
<pre><code>##             y x1=A x1=B x1=C x2=U x2=V x2=W x2=X
## [1,] 1.205632    1    0    0    0    0    0    0
## [2,] 2.197258    1    0    0    0    0    0    0
## [3,] 3.001704    1    0    0    0    0    0    0
## [4,] 3.288825    1    0    0    0    0    0    0
## [5,] 2.905753    1    0    0    0    0    0    0
## [6,] 2.493667    1    0    0    0    0    0    1
##      x2=Y x2=Z
## [1,]    0    1
## [2,]    0    1
## [3,]    0    1
## [4,]    0    1
## [5,]    0    1
## [6,]    0    0</code></pre>
<p><strong>Reference-level coding </strong></p>
<p>Reference-level coding is similar to one-hot encoding except one of the levels of the attribute, called the <strong>reference level</strong>, is omitted. Notice that the 4 dummy columns from Table <a href="intro-stat.html#tab:onehot">1.1</a> collectively form a linearly dependent set; that is, if you know the values of 3 of the 4 dummy variables you can determine the <span class="math inline">\(4^{th}\)</span> with complete certainty. This would be a problem for linear regression, where we assume our input attributes are not linearly dependent as we will discuss in Chapter <a href="slr.html#slr">2</a>.</p>
<p>A reference level of the attribute is often specified by the user to be a particular level worthy of comparison (a baseline), as the regression output will be interpreted in a way that compares each non-reference level to the reference level. If a reference level is not specified by the user, one will be picked by the software by default either using the order in which the levels were encountered in the data, or their alphabetical ordering. Users should check the documentation of the associated function to understand what to expect.</p>
<p>Table <a href="intro-stat.html#tab:refcoding">1.2</a> transforms the one-hot encoding from Table <a href="intro-stat.html#tab:onehot">1.1</a> into reference-level coding with the color “blue” as the reference level. Notice the absence of the column indicating “blue” and how each blue observation exists as a row of zeros.</p>
<table>
<tr>
<td>
Observation
<td>
Color
<td>
Red
<td>
Yellow
<td>
Other
</tr>
<tr>
<td>
1
<td>
Blue
<td>
0
<td>
0
<td>
0
</tr>
<tr>
<td>
2
<td>
Yellow
<td>
0
<td>
1
<td>
0
</tr>
<tr>
<td>
3
<td>
Blue
<td>
0
<td>
0
<td>
0
</tr>
<tr>
<td>
4
<td>
Red
<td>
1
<td>
0
<td>
0
</tr>
<tr>
<td>
5
<td>
Red
<td>
1
<td>
0
<td>
0
</tr>
<tr>
<td>
6
<td>
Blue
<td>
0
<td>
0
<td>
0
</tr>
<tr>
<td>
7
<td>
Yellow
<td>
0
<td>
1
<td>
0
</tr>
<tr>
<td>
8
<td>
Other
<td>
0
<td>
0
<td>
1
</tr>
</table>
<caption>
<span id="tab:refcoding">Table 1.2: </span> Reference-level dummy variable coding for the categorical attribute <em>color</em> and the reference level of “blue”
</caption>
<p><strong>Effects coding</strong></p>
<p>Effects coding is useful for obtaining a more general comparative interpretation when you have approximately equal sample sizes across each level of your categorical attribute. Effects coding is designed to allow the user to compare each level to <em>all</em> the other levels. More specifically the mean of each level is compared to the <strong>overall mean</strong> of your data. However, the comparison is actually to the so-called <em>grand mean</em>, which is the mean of the means of each group. When sample sizes are equal, the grand mean and the overall sample mean are equivalent. When sample sizes are <em>not</em> equal, the parameter estimates for effects coding should not be used for interpretation or explanation.</p>
<p>Effects coding still requires a <em>reference level</em>, however the purpose of the reference level is not the same as it was in reference-level coding. Here, the reference level is left out in the sense that no comparison is made between it and the overall mean. Table <a href="intro-stat.html#tab:effcoding">1.3</a> shows our same example with effects coding. Again we notice the absence of the column indicating “blue” but now the reference level receives values of <code>-1</code> rather than <code>0</code> for all 3 dummy columns. We will revisit the interpretation of linear regression coefficients under this coding scheme in Chapter <a href="slr.html#slr">2</a>.</p>
<table>
<tr>
<td>
Observation
<td>
Color
<td>
Red
<td>
Yellow
<td>
Other
<tr>
<td>
1
<td>
Blue
<td>
-1
<td>
-1
<td>
-1
<tr>
<td>
2
<td>
Yellow
<td>
0
<td>
1
<td>
0
<tr>
<td>
3
<td>
Blue
<td>
-1
<td>
-1
<td>
-1
<tr>
<td>
4
<td>
Red
<td>
1
<td>
0
<td>
0
<tr>
<td>
5
<td>
Red
<td>
1
<td>
0
<td>
0
<tr>
<td>
6
<td>
Blue
<td>
-1
<td>
-1
<td>
-1
<tr>
<td>
7
<td>
Yellow
<td>
0
<td>
1
<td>
0
<tr>
<td>
8
<td>
Other
<td>
0
<td>
0
<td>
1
</table>
<caption>
<span id="tab:effcoding">Table 1.3: </span> Effects coding for the categorical attribute <em>color</em> and the reference level of “blue”
</caption>
</div>
<div id="interval-variables" class="section level4 unnumbered hasAnchor">
<h4>Interval Variables<a href="intro-stat.html#interval-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>An interval variable is a <em>quantity of interest</em> on which the mathematical operations of addition, subtraction, multiplication and division can be performed. Time, temperature and age are all examples of interval attributes. To illustrate the definition, note that “15 minutes” divided by “5 minutes” is 3, which indicates that 15 minutes is 3 times as long as 5 minutes. The sensible interpretation of this simple arithmetic sentence demonstrates the nature of interval attributes. One should note that such arithmetic would not make sense in the treatment of nominal variables.</p>
</div>
<div id="ordinal-variables" class="section level4 unnumbered hasAnchor">
<h4>Ordinal Variables<a href="intro-stat.html#ordinal-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Ordinal variables</strong> are attributes that are qualitative in nature but have some natural ordering. <em>Level of education</em> is a common example, with a level of ‘PhD’ indicating <em>more</em> education than ‘Bachelors’ but lacking a numerical framework to quantify <em>how much more</em>. The treatment of ordinal variables will depend on the application. Survey responses on a Likert scale are also ordinal - a response of 4=“somewhat agree” on a 1-to-5 scale of agreement cannot reliably be said to be twice as enthusiastic as a response of 2=“somewhat disagree”. These are not interval measurements, though they are often treated as such in a trade-off for computational efficiency.</p>
<p><strong>Ordinal variables will either be given some numeric value and treated as interval variables or they will be treated as categorical variables and dummy variables will be created. The choice of solution is up to the analyst.</strong> When numeric values are assigned to ordinal variables, the possibilities are many. For example, consider <em>level of education</em>. The simplest ordinal treatment for such an attribute might be something like Table <a href="intro-stat.html#tab:educationint">1.4</a>.</p>
<table>
<tr>
<td>
Level of Education
<td>
Numeric Value
<tr>
<td>
No H.S. Diploma
<td>
1
<tr>
<td>
H.S. Diploma or GED
<td>
2
<tr>
<td>
Associates or Certificate
<td>
3
<tr>
<td>
Bachelors
<td>
4
<tr>
<td>
Graduate Certificate
<td>
5
<tr>
<td>
Masters
<td>
6
<tr>
<td>
PhD
<td>
7
</table>
<caption>
<span id="tab:educationint">Table 1.4: </span> One potential approach to scaling the ordinal attribute level of education
</caption>
<p>While numeric values have been assigned and this data <em>could</em> be used like an interval attribute, it’s important to realize that the notion of a “one-unit increase” is qualitative in nature rather than quantitative. However, if we’re interested in learning whether there is a <em>linear</em> type of relationship between education and another attribute (meaning as education level increases, the value of another attribute increases or decreases), this would be the path to get us there. However we’re making an assumption in this model that the difference between a H.S. Diploma and an Associates degree (a difference of “1 unit”) is the same as the difference between a Master’s degree and a PhD (also a difference of “1 unit”). These types of assumptions can be flawed, and it is often desirable to develop an alternative system of measurement based either on domain expertise or the target variable of interest. This is the notion behind <strong>optimal scaling</strong> and <strong>target-level encoding</strong>.</p>
<p><strong>Optimal Scaling</strong></p>
<p>The primary idea behind optimal scaling is to transform an ordinal attribute into an interval one in a way that doesn’t restrict the numeric values to simply the integers <span class="math inline">\(1,2,3, \dots\)</span>. It’s reasonable for a data scientist to use domain expertise to develop an alternative scheme.</p>
<p>For example, if analyzing movie theater concessions with ordinal drink sizes {small, medium, large}, one is not restricted to the numeric valuation of 1=small, 2=medium, and 3=large just because it’s an ordinal variable with 3 levels. Perhaps it would make more sense to use the drink size in fluid ounces to represent the ordinality. If the small drink is 12 ounces, the medium is 20 ounces, and the large is 48 ounces, then using those values as the numerical representation would be every bit as (if not more) reasonable than using the standard integers 1, 2, and 3.</p>
<p>If we re-consider the ordinal attribute level of education, we might decide to represent the approximate years of post-secondary schooling required to obtain a given level. This might lead us to something like the attribute values in Table <a href="intro-stat.html#tab:educationscaled">1.5</a>.</p>
<table>
<tr>
<td>
Level of Education
<td>
Numeric Value
<tr>
<td>
No H.S. Diploma
<td>
-1
<tr>
<td>
H.S. Diploma or GED
<td>
0
<tr>
<td>
Associate’s or Certificate
<td>
2
<tr>
<td>
Bachelor’s
<td>
4
<tr>
<td>
Graduate Certificate
<td>
5
<tr>
<td>
Master’s
<td>
6
<tr>
<td>
PhD
<td>
8
</table>
<caption>
<span id="tab:educationscaled">Table 1.5: </span> One potential approach to scaling the ordinal attribute level of education
</caption>
<p>If we were modeling the effect of education on something like salary, it seems reasonable to assume that the jumps between levels should not have equal distance like they did in <a href="intro-stat.html#tab:educationint">1.4</a>. It seems reasonable to assume that one would experience a larger salary lift from Associate’s to Bachelor’s degree than they would from No H.S. Diploma to GED. The most common way to determine the numeric values for categories is to use information from the response variable. This is commonly referred to as <strong>target level encoding</strong>.</p>
<p><strong>Target Level Encoding</strong></p>
<p>The values in Table <a href="intro-stat.html#tab:educationscaled">1.5</a> might have struck the reader as logical but arbitrary. To be more scientific about the determination of those numeric values, one might wish to use information from the response variable to obtain a more precise expected change in salary for each level increase in education. At first hearing this, one might question the validity of the technique; isn’t the goal to <em>predict</em> salary? This line of thought is natural, but there are no concerns here. As long as we have training data (and we must if we’re creating a regression model!), we can simply create a look-up table that matches each level of education to the average or median salary obtained for that level. These values can be used just as readily as the arbitrary levels created in Table <a href="intro-stat.html#tab:educationscaled">1.5</a> to encode the ordinal attribute!</p>
</div>
</div>
<div id="dist" class="section level3 hasAnchor" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Distributions<a href="intro-stat.html#dist" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>After reviewing the types and formats of the data inputs, we move on to some basic <strong>univariate</strong> (one variable at a time) analysis. We start by describing the distribution of values that each variable takes on. For nominal variables, this amounts to frequency tables and bar charts of how often each level of the variable appears in the data set.</p>
<p>We’ll begin by exploring one of our nominal features, <code>Heating_QC</code> which categorizes the quality and condition of a home’s heating system. To create plots in R, we will use the popular <code>ggplot2</code> library. At the same time, we will load the <code>tidyverse</code> library which we will use in the next chunk of code.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="intro-stat.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb8-2"><a href="intro-stat.html#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb8-3"><a href="intro-stat.html#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames) <span class="sc">+</span></span>
<span id="cb8-4"><a href="intro-stat.html#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Heating_QC))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:barchart"></span>
<img src="bookdownproj_files/figure-html/barchart-1.png" alt="Distribution of Nominal Variable Heating_QC" width="672" />
<p class="caption">
Figure 1.1: Distribution of Nominal Variable Heating_QC
</p>
</div>
<p>To summon the same information in tabular form, we can use the <code>count()</code> function to create a table:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="intro-stat.html#cb9-1" aria-hidden="true" tabindex="-1"></a>ames <span class="sc">%&gt;%</span> </span>
<span id="cb9-2"><a href="intro-stat.html#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(Heating_QC)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   Heating_QC     n
##   &lt;ord&gt;      &lt;int&gt;
## 1 Poor           3
## 2 Fair          92
## 3 Typical      864
## 4 Good         476
## 5 Excellent   1495</code></pre>
<p>You’ll notice that very few houses (3) have heating systems in <code>Poor</code> condition, and the majority of houses have systems rated <code>Excellent</code>. <strong>It will likely make sense to combine the categories of <code>Fair</code> and <code>Poor</code> in our eventual analysis, a decision we will later revisit.</strong></p>
<p>Next we create a <strong>histogram</strong> for an interval attribute like <code>Sale_Price</code>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="intro-stat.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames) <span class="sc">+</span></span>
<span id="cb11-2"><a href="intro-stat.html#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span> </span>
<span id="cb11-3"><a href="intro-stat.html#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sales Price (Thousands $)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:histogram"></span>
<img src="bookdownproj_files/figure-html/histogram-1.png" alt="Distribution of Interval Variable Sale_Price" width="672" />
<p class="caption">
Figure 1.2: Distribution of Interval Variable Sale_Price
</p>
</div>
<p>From this initial inspection, we can conclude that most of the houses sell for less than $200,000 and there are a number of expensive anomalies. To more concretely describe and quantify a statistical distribution, we use statistics that describe the <em>location, spread, and shape</em> of the data.</p>
<div id="location" class="section level4 unnumbered hasAnchor">
<h4>Location<a href="intro-stat.html#location" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <em>location</em> of a distribution refers to the x-axis of a histogram like that in Figure <a href="intro-stat.html#fig:histogram">1.2</a>. Where is most of the data located? The sample <strong>mean</strong>, <strong>median</strong>, and <strong>mode</strong> are the most common statistics of location, but <strong>percentiles</strong> and the <strong>interquartile range</strong> can also be seen in this light.</p>
<p>We define each of these terms below for a variable <span class="math inline">\(\mathbf{x}\)</span> having n observations with values <span class="math inline">\(\{x_i\}_{i=1}^n\)</span>, sorted in order of magnitude such that <span class="math inline">\(x_1 \leq x_2 \leq \dots \leq x_n\)</span>:</p>
<ul>
<li>
Mean: The <strong>average</strong> of the observations, <span class="math inline">\(\bar{\mathbf{x}}= \frac{1}{n}\sum_{i=1}^n x_i\)</span>
<li>
Median: The “middle value” of the data. Formally, when <span class="math inline">\(n\)</span> is odd, the median is the observation value, <span class="math inline">\(x_m = x_{\frac{(n+1)}{2}}\)</span> for which <span class="math inline">\(x_i &lt; x_m\)</span> for 50% of the observations (excluding <span class="math inline">\(x_m\)</span>). When <span class="math inline">\(n\)</span> is even, <span class="math inline">\(x_m\)</span> is the average of <span class="math inline">\(x_\frac{n}{2}\)</span> and <span class="math inline">\(x_{(\frac{n}{2}+1)}\)</span>. The median is also known as the <span class="math inline">\(2^{nd}\)</span> <strong>quartile</strong>.
<li>
Mode: The most commonly occurring value in the data. Most commonly used to describe nominal attributes.
<li>
Percentiles: The 99 intermediate values of the data which divide the observations into 100 equally-sized groups. The <span class="math inline">\(r^{th}\)</span> percentile of the data, <span class="math inline">\(P_r\)</span> is the number for which <span class="math inline">\(r\%\)</span> of the data is less than <span class="math inline">\(P_r\)</span>.
<li>
Quartiles: The quartiles of a variable are the <span class="math inline">\(25^{th}\)</span>, <span class="math inline">\(50^{th}\)</span>, and <span class="math inline">\(75^{th}\)</span> percentiles. They are denoted as <span class="math inline">\(Q_1\)</span> (<span class="math inline">\(1^{st}\)</span> quartile), <span class="math inline">\(Q_2\)</span> (<span class="math inline">\(2^{nd}\)</span> quartile = median), and <span class="math inline">\(Q_3\)</span> (<span class="math inline">\(3^{rd}\)</span> quartile) respectively.
</ul>
<p><strong>Example</strong></p>
<p>The following table contains the heights of 10 students randomly sampled from NC State’s campus. Compute the mean, median, mode and quartiles of this variable.</p>
<table style="width:auto; margin-left: auto; margin-right: auto;" >
<tr>
<td style="text-align:center">
height
<td style="text-align:center">
60
<td style="text-align:center">
62
<td style="text-align:center">
63
<td style="text-align:center">
65
<td style="text-align:center">
67
<td style="text-align:center">
67
<td style="text-align:center">
67
<td style="text-align:center">
68
<td style="text-align:center">
68
<td style="text-align:center">
69
</table>
<p><strong>Solution:</strong></p>
<ul>
<li>
The mean is <code>(60+62+63+65+67+67+67+68+68+69)/10</code> = 65.6.
<li>
The median (second quartile) is <code>(67+67)/2</code> = 67.
<li>
The mode is 67.
<li>
The first quartile is <code>(62+63)/2</code> = 62.5
<li>
The third quartile is <code>(68+68)/2</code> = 68
</ul>
</div>
<div id="spread" class="section level4 unnumbered hasAnchor">
<h4>Spread<a href="intro-stat.html#spread" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Once we have an understanding of where the bulk of the data is located, we move on to describing the spread (the dispersion or variation) of the data. <strong>Range</strong>, <strong>interquartile range</strong>, <strong>variance</strong>, and <strong>standard deviation</strong> are all statistics that describe spread.</p>
<ul>
<li>
Range: The difference between the maximum and minimum data values.
<li>
Interquartile range (IQR): The difference between the <span class="math inline">\(25^{th}\)</span> and <span class="math inline">\(75^{th}\)</span> percentiles.
<li>
Sample variance: The sum of squared differences between each data point and the mean, divided by (n-1). <span class="math inline">\(\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar{x})^2\)</span>
<li>
<p>Standard deviation: The square root of the sample variance.</p>
<p>One should note that standard deviation is more frequently reported than variance because it shares the same units as the original data, and because of the guidance provided by the empirical rule. If we’re exploring something like <code>Sale_Price</code>, which has the unit “dollars”, then the variance would be measured in “square-dollars”, which hampers the intuition. Standard deviation, on the other hand, would share the unit “dollars”, aiding our fundamental understanding.</p>
<p><strong>Example </strong>
Let’s again use the table of heights from the previous example, this time computing the range, IQR, sample variance and standard deviation.</p>
<table style="width:auto; margin-left: auto; margin-right: auto;" >
<tr>
<td style="text-align:center">
height
<td style="text-align:center">
60
<td style="text-align:center">
62
<td style="text-align:center">
63
<td style="text-align:center">
65
<td style="text-align:center">
67
<td style="text-align:center">
67
<td style="text-align:center">
67
<td style="text-align:center">
68
<td style="text-align:center">
68
<td style="text-align:center">
69
</table>
<p><strong>Solution:</strong></p>
<ul>
<li>
The range <code>69-60</code> = 9.
<li>
The IQR is <code>68 - 62.5</code> = 5.5.
<li>
The variance is <code>((60-65.6)^2+(62-65.6)^2+(63-65.6)^2+(65-65.6)^2+(67-65.6)^2+(67-65.6)^2+(67-65.6)^2+(68-65.6)^2+(68-65.6)^2+(69-65.6)^2)/9</code> = 8.933
<li>
The standard deviation is <code>sqrt(8.933)</code> = 2.989
</ul>
</div>
<div id="shape" class="section level4 unnumbered hasAnchor">
<h4>Shape<a href="intro-stat.html#shape" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The final description we will want to give to distributions regards their shape. Is the histogram <em>symmetric</em>? Is it <em>unimodal</em> (having a single large “heap” of data) or <em>multimodal</em> (having multiple heaps”)? Does it have a longer tail on one side than the other (<em>skew</em>)? Is there a lot more or less data in the tails than you might expect?</p>
<p>We’ll formalize these ideas with some illustrations. A distribution is right (left) skewed if it has a longer tail on its right (left) side, as shown in Figure <a href="intro-stat.html#fig:skewdiagram">1.3</a>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="intro-stat.html#cb12-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">&quot;img/skewdiagrams.png&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:skewdiagram"></span>
<img src="img/skewdiagrams.png" alt="Examples of Left-Skewed (Negative Skew) and Right-skewed (Positive Skew) distributions respectively" width="100%" />
<p class="caption">
Figure 1.3: Examples of Left-Skewed (Negative Skew) and Right-skewed (Positive Skew) distributions respectively
</p>
</div>
<p>A distribution is called <em>bimodal</em> if it has two “heaps”, as shown in Figure <a href="intro-stat.html#fig:bimodal">1.4</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bimodal"></span>
<img src="img/bimodal.png" alt="Example of a Bimodal Distribution" width="50%" />
<p class="caption">
Figure 1.4: Example of a Bimodal Distribution
</p>
</div>
</div>
<div id="summary-functions-in-r" class="section level4 unnumbered hasAnchor">
<h4>Summary Functions in R<a href="intro-stat.html#summary-functions-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There are many ways to obtain all of the statistics described in the preceding sections, below we highlight 3:</p>
<ol>
<li>
<p>The <code>describe</code> function from the <code>Hmisc</code> package which can work on the entire dataset or a subset of columns.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="intro-stat.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb13-2"><a href="intro-stat.html#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="intro-stat.html#cb13-3" aria-hidden="true" tabindex="-1"></a>Hmisc<span class="sc">::</span><span class="fu">describe</span>(ames<span class="sc">$</span>Sale_Price)</span></code></pre></div>
<pre><code>## ames$Sale_Price 
##        n  missing distinct     Info     Mean 
##     2930        0     1032        1   180796 
##      Gmd      .05      .10      .25      .50 
##    81960    87500   105450   129500   160000 
##      .75      .90      .95 
##   213500   281242   335000 
## 
## lowest :  12789  13100  34900  35000  35311
## highest: 611657 615000 625000 745000 755000</code></pre>
<li>
<p>The tidyverse <code>summarise</code> function, in this case obtaining statistics for each <code>Exter_Qual</code> separately.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="intro-stat.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb15-2"><a href="intro-stat.html#cb15-2" aria-hidden="true" tabindex="-1"></a>ames <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(Exter_Qual) <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">summarise</span>(<span class="at">average =</span> <span class="fu">mean</span>(Sale_Price), <span class="at">st.dev =</span> <span class="fu">sd</span>(Sale_Price), <span class="at">maximum =</span> <span class="fu">max</span>(Sale_Price), <span class="at">minimum =</span> <span class="fu">min</span>(Sale_Price))</span></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   Exter_Qual average  st.dev maximum minimum
##   &lt;ord&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;
## 1 Fair        89924.  38014.  200000   13100
## 2 Typical    143374.  41504.  415000   12789
## 3 Good       230756.  70411.  745000   52000
## 4 Excellent  377919. 106988.  755000  160000</code></pre>
<li>
<p>The base R <code>summary</code> function, which can work on the entire dataset or an individual variable</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="intro-stat.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ames<span class="sc">$</span>Sale_Price)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   12789  129500  160000  180796  213500  755000</code></pre>
</div>
</div>
<div id="normal" class="section level3 hasAnchor" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> The Normal Distribution<a href="intro-stat.html#normal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
The normal distribution, also known as the Gaussian distribution, is one of the most fundamental concepts in statistics. It is one that arises naturally out of many applications and settings. The normal distribution has the following characteristics:
<ol>
<li>
Symmetric
<li>
Fully defined by mean and standard deviation (equivalently, variance)
<li>
Bell-shaped/Unimodal
<li>
Mean = Median = Mode
<li>
Assymptotic to the x-axis (theoretical bounds are <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>)
</ol>
<p>Much of the normal distributions utility can be summarized in the <strong>empirical rule</strong>, which states that:</p>
<ul>
<li>
<span class="math inline">\(\approx\)</span> 68% of data in normal distribution lies within 1 standard deviation of the mean.
<li>
<span class="math inline">\(\approx\)</span> 95% of data in normal distribution lies within 2 standard deviations of the mean.
<li>
<span class="math inline">\(\approx\)</span> 99.7% of data in normal distribution lies within 3 standard deviations of the mean.
</ul>
<p>We can thus conclude that observations found outside of 3 standard deviations from the mean are quite rare, expected less than 1% of the time.</p>
</div>
<div id="skew" class="section level3 hasAnchor" number="1.1.4">
<h3><span class="header-section-number">1.1.4</span> Skewness<a href="intro-stat.html#skew" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Skewness is a statistic that describes the symmetry (or lack thereof) of a distribution. A normal distribution is perfectly symmetric and has a skewness of 0. Distributions that are more right skewed will have positive values of skewness whereas distributions that are more left skewed will have negative values of skewness.</p>
</div>
<div id="kurt" class="section level3 hasAnchor" number="1.1.5">
<h3><span class="header-section-number">1.1.5</span> Kurtosis<a href="intro-stat.html#kurt" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Kurtosis is a statistic that describes the <em>tailedness</em> of a distribution. The normal distribution has a kurtosis of 3. Distributions that are more tailed (leptokurtic or heavy-tailed) will have kurtosis values greater than 3 whereas distributions that are more less tailed (platykurtic or thin-tailed) will have values of kurtosis less than 3. For this reason, kurtosis is often reported in the form of <em>excess kurtosis</em> which is the raw kurtosis value minus 3. This is meant as a comparison to the normal distribution so that positive values indicate thicker tails and negative values indicate thinner tails than the normal.</p>
<p>In Figure <a href="intro-stat.html#fig:kurtosis">1.5</a> below, we compare classical examples of leptokurtic and platykurtic distributions to a normal distribution with the same mean and variance.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kurtosis"></span>
<img src="bookdownproj_files/figure-html/kurtosis-1.png" alt="The Laplace distribution (top left) is leptokurtic because it has more data in its tails than the normal distribution with the same mean and variance. The uniform distribution (top right) is platykurtic because it has less data in its tails than the normal distribution with the same mean and variance (it effectively has no tails)." width="672" />
<p class="caption">
Figure 1.5: The Laplace distribution (top left) is leptokurtic because it has more data in its tails than the normal distribution with the same mean and variance. The uniform distribution (top right) is platykurtic because it has less data in its tails than the normal distribution with the same mean and variance (it effectively has no tails).
</p>
</div>
</div>
<div id="graphdist" class="section level3 hasAnchor" number="1.1.6">
<h3><span class="header-section-number">1.1.6</span> Graphical Displays of Distributions<a href="intro-stat.html#graphdist" class="anchor-section" aria-label="Anchor link to header"></a></h3>
There are three types of plots for examining the distribution of your data values:
<ol>
<li>
Histograms
<li>
Normal Probability Plots (QQ-plots)
<li>
<p>Box Plots</p>
<div id="histograms" class="section level4 unnumbered hasAnchor">
<h4>Histograms<a href="intro-stat.html#histograms" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A histogram shows the shape of a univariate distribution. Each bar in the histogram represents a group of values (a <em>bin</em>). The height of the bar represents the either the frequency of or the percent of values in the bin. The width and number of bins is determined automatically, but the user can adjust them to see more or less detail in the histogram. Figure <a href="intro-stat.html#fig:histogram">1.2</a> demonstrated a histogram of sale price. Sometimes it’s nice to overlay a continuous approximation to the underlying distribution using a <em>kernal density estimator</em> with the <code>geom_density</code> plot, demonstrated in Figure <a href="intro-stat.html#fig:histwithkernal">1.6</a>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="intro-stat.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ames,<span class="fu">aes</span>(<span class="at">x=</span>Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span> </span>
<span id="cb19-2"><a href="intro-stat.html#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y=</span>..density..), <span class="at">alpha=</span><span class="fl">0.5</span>) <span class="sc">+</span> <span class="fu">geom_density</span>( <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb19-3"><a href="intro-stat.html#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sales Price (Thousands $)&quot;</span>)  </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:histwithkernal"></span>
<img src="bookdownproj_files/figure-html/histwithkernal-1.png" alt="Histogram of Sale_Price with kernal density estimator" width="672" />
<p class="caption">
Figure 1.6: Histogram of Sale_Price with kernal density estimator
</p>
</div>
<p>In our next example, Figure <a href="intro-stat.html#fig:overhistogramAC">1.7</a>, we’ll complicate the previous example by showing <em>two</em> distributions of sale price, one for each level of the binary variable <code>Central_Air</code>, overlaid on the same axes.</p>
<p>We can immediately see that there are many more houses that have central air than do not in this data. It appears as though the two distributions have different locations, with the pink distribution centered at a larger sale price. To normalize that quantity and compare the raw probability densitites, we can change our axes to density as in Figure <a href="intro-stat.html#fig:overhistogramdensityAC">1.8</a>.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="intro-stat.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ames,<span class="fu">aes</span>(<span class="at">x=</span>Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span> </span>
<span id="cb20-2"><a href="intro-stat.html#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">data=</span><span class="fu">subset</span>(ames,Central_Air <span class="sc">==</span> <span class="st">&#39;Y&#39;</span>),<span class="fu">aes</span>(<span class="at">fill=</span>Central_Air), <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb20-3"><a href="intro-stat.html#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">data=</span><span class="fu">subset</span>(ames,Central_Air <span class="sc">==</span> <span class="st">&#39;N&#39;</span>),<span class="fu">aes</span>(<span class="at">fill=</span>Central_Air), <span class="at">alpha  =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb20-4"><a href="intro-stat.html#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sales Price (Thousands $)&quot;</span>)  <span class="sc">+</span> <span class="fu">scale_fill_manual</span>(<span class="at">name=</span><span class="st">&quot;Central_Air&quot;</span>,<span class="at">values=</span><span class="fu">c</span>(<span class="st">&quot;red&quot;</span>,<span class="st">&quot;blue&quot;</span>),<span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;No&quot;</span>,<span class="st">&quot;Yes&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:overhistogramAC"></span>
<img src="bookdownproj_files/figure-html/overhistogramAC-1.png" alt="Histogram: Frequency of Sale_Price for Each value of Central_Air" width="672" />
<p class="caption">
Figure 1.7: Histogram: Frequency of Sale_Price for Each value of Central_Air
</p>
</div>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="intro-stat.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ames,<span class="fu">aes</span>(<span class="at">x=</span>Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span> </span>
<span id="cb21-2"><a href="intro-stat.html#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">data=</span><span class="fu">subset</span>(ames,Central_Air <span class="sc">==</span> <span class="st">&#39;Y&#39;</span>),<span class="fu">aes</span>(<span class="at">y=</span>..density..,<span class="at">fill=</span>Central_Air), <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb21-3"><a href="intro-stat.html#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>(<span class="at">data=</span><span class="fu">subset</span>(ames,Central_Air <span class="sc">==</span> <span class="st">&#39;N&#39;</span>),<span class="fu">aes</span>(<span class="at">y=</span>..density..,<span class="at">fill=</span>Central_Air), <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb21-4"><a href="intro-stat.html#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sales Price (Thousands $)&quot;</span>) </span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value
## with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value
## with `binwidth`.</code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:overhistogramdensityAC"></span>
<img src="bookdownproj_files/figure-html/overhistogramdensityAC-1.png" alt="Histogram: Density of Sale_Price for varying qualities of  Central_Air" width="672" />
<p class="caption">
Figure 1.8: Histogram: Density of Sale_Price for varying qualities of Central_Air
</p>
</div>
<p>To ease our differentiation of the histograms even further, we again employ a kernel density estimator as shown in Figure <a href="intro-stat.html#fig:overhistogramdensitykernelAC">1.9</a>. This is an appealing alternative to the histogram for continuous data that is assumed to originate from some smooth underlying distribution.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="intro-stat.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ames,<span class="fu">aes</span>(<span class="at">x=</span>Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span> </span>
<span id="cb23-2"><a href="intro-stat.html#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_density</span>(<span class="at">data=</span><span class="fu">subset</span>(ames,Central_Air <span class="sc">==</span> <span class="st">&#39;Y&#39;</span>),<span class="fu">aes</span>(<span class="at">fill=</span>Central_Air), <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb23-3"><a href="intro-stat.html#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_density</span>(<span class="at">data=</span><span class="fu">subset</span>(ames,Central_Air <span class="sc">==</span> <span class="st">&#39;N&#39;</span>),<span class="fu">aes</span>(<span class="at">fill=</span>Central_Air), <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb23-4"><a href="intro-stat.html#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sales Price (Thousands $)&quot;</span>)  </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:overhistogramdensitykernelAC"></span>
<img src="bookdownproj_files/figure-html/overhistogramdensitykernelAC-1.png" alt="Histogram: Density of Sale_Price for varying qualities of Central_Air" width="672" />
<p class="caption">
Figure 1.9: Histogram: Density of Sale_Price for varying qualities of Central_Air
</p>
</div>
</div>
<div id="normal-probability-plots-qq-plots" class="section level4 unnumbered hasAnchor">
<h4>Normal probability plots (QQ Plots)<a href="intro-stat.html#normal-probability-plots-qq-plots" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A <strong>normal probability plot</strong> graphs the sorted data values against the values that one would expect if the same number of observations came from a theoretical normal distribution. The resulting image would look close to a straight line if the data was generated by a normal distribution. Strong deviations from a straight line indicate that the data distribution is not normal.</p>
<p>Figure <a href="intro-stat.html#fig:qqplot">1.10</a> shows a QQ plot for <code>Sale_Price</code>, and we can conclude that the variable is not normally distributed.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="intro-stat.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames, <span class="fu">aes</span>(<span class="at">sample =</span> Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span></span>
<span id="cb24-2"><a href="intro-stat.html#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb24-3"><a href="intro-stat.html#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qqplot"></span>
<img src="bookdownproj_files/figure-html/qqplot-1.png" alt="QQ-Plot: Quantiles of Sale_Price vs. quantiles of a theoretical normal distribution with same mean and standard deviation. Conclusion: Sale_Price is _not_ normally distributed due to a problem with skew." width="672" />
<p class="caption">
Figure 1.10: QQ-Plot: Quantiles of Sale_Price vs. quantiles of a theoretical normal distribution with same mean and standard deviation. Conclusion: Sale_Price is <em>not</em> normally distributed due to a problem with skew.
</p>
</div>
There are two main patterns that we expect to find when examining QQ-plots:
<ol>
<li>
A quadratic shape, as seen in Figure <a href="intro-stat.html#fig:qqplot">1.10</a>. This pattern indicates a deviation from normality due to skewness to the data.
<li>
An S-shape (or cubic shape), as seen in Figure <a href="intro-stat.html#fig:qqplotKurt">1.11</a>. This pattern indicates deviation from normality due to kurtosis.
</ol>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="intro-stat.html#cb25-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">j1 =</span> <span class="fu">rlaplace</span>(<span class="dv">10000</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb25-2"><a href="intro-stat.html#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="intro-stat.html#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> df, <span class="fu">aes</span>(<span class="at">sample=</span>j1)) <span class="sc">+</span></span>
<span id="cb25-4"><a href="intro-stat.html#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb25-5"><a href="intro-stat.html#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qqplotKurt"></span>
<img src="bookdownproj_files/figure-html/qqplotKurt-1.png" alt="QQ-Plot: Quantiles of the Laplace distribution vs. quantiles of a theoretical normal distribution with same mean and standard deviation. Conclusion: Data is _not_ normally distributed, due to a problem with kurtosis." width="672" />
<p class="caption">
Figure 1.11: QQ-Plot: Quantiles of the Laplace distribution vs. quantiles of a theoretical normal distribution with same mean and standard deviation. Conclusion: Data is <em>not</em> normally distributed, due to a problem with kurtosis.
</p>
</div>
</div>
<div id="box-plots" class="section level4 unnumbered hasAnchor">
<h4>Box Plots<a href="intro-stat.html#box-plots" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Box plots (sometimes called box-and-whisker plots) wont necessarily tell you about the <em>shape</em> of your distribution (for instance a bimodal distribution could have a similar box plot to a unimodal one), but it will give you a sense of the distribution’s location and spread.</p>
<p>Many of us have become familiar with the <em>idea</em> of a box plot, but when pressed for the specific steps to create one, we realize our familiarity fades. The diagram in Figure <a href="intro-stat.html#fig:boxplot">1.12</a> will remind the reader the precise information conveyed by a box plot.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:boxplot"></span>
<img src="img/boxplot.png" alt="Anatomy of a Box Plot." width="110%" />
<p class="caption">
Figure 1.12: Anatomy of a Box Plot.
</p>
</div>
<p>Figure <a href="intro-stat.html#fig:rboxplot">1.13</a> shows the boxplot of <code>Sale_Price</code>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="intro-stat.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames, <span class="fu">aes</span>(<span class="at">y =</span> Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span> </span>
<span id="cb26-2"><a href="intro-stat.html#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span> </span>
<span id="cb26-3"><a href="intro-stat.html#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Sales Price (Thousands $)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rboxplot"></span>
<img src="bookdownproj_files/figure-html/rboxplot-1.png" alt="Box Plot of Sale_Price" width="672" />
<p class="caption">
Figure 1.13: Box Plot of Sale_Price
</p>
</div>
<p>Furthermore, we might want to compare the boxplots of <code>Sale_Price</code> for different levels of a categorical variable, like <code>Central_Air</code> as we did with histograms and densities in Figures <a href="intro-stat.html#fig:overhistogramAC">1.7</a> and <a href="intro-stat.html#fig:overhistogramdensityAC">1.8</a>.</p>
<p>The following code achieves this goal in Figure <a href="intro-stat.html#fig:multiboxplotAC">1.14</a>.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="intro-stat.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames, <span class="fu">aes</span>(<span class="at">y =</span> Sale_Price<span class="sc">/</span><span class="dv">1000</span>, <span class="at">x =</span> Central_Air, <span class="at">fill =</span> Central_Air)) <span class="sc">+</span> </span>
<span id="cb27-2"><a href="intro-stat.html#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span> </span>
<span id="cb27-3"><a href="intro-stat.html#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Sales Price (Thousands $)&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Central Air&quot;</span>) <span class="sc">+</span></span>
<span id="cb27-4"><a href="intro-stat.html#cb27-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_brewer</span>(<span class="at">palette=</span><span class="st">&quot;Accent&quot;</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>() <span class="sc">+</span> <span class="fu">coord_flip</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:multiboxplotAC"></span>
<img src="bookdownproj_files/figure-html/multiboxplotAC-1.png" alt="Box Plots of Sale_Price for each level of Exter_Qual" width="672" />
<p class="caption">
Figure 1.14: Box Plots of Sale_Price for each level of Exter_Qual
</p>
</div>
</div>
</div>
</div>
<div id="pointest" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Point Estimates<a href="intro-stat.html#pointest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>All the statistics discussed so far have been <em>point estimates</em>. They are our <em>best</em> estimate at what the population parameter might be, but since we’ve taken a random sample of data from that population, there must be some uncertainty surrounding that estimate. In statistics, our real interest lies in drawing inferences about an entire population (which we couldn’t possibly observe due to time, cost, and/or feasibility constraints) and our approach is to take a representative sample and try to understand what it might tell us about the population.</p>
<p>For the remainder of this text, we will assume our sample is representative of the population. Let’s review some common statistical notation of <em>population parameters</em> (the true values we couldn’t possibly observe) and <em>sample statistics</em> (those values we calculate based on our sample)</p>
<table style = "width: 65%;margin-left: auto;margin-right: auto">
<tr>
<td style="text-align:center">
<b> Population Parameter </b>
<td style="text-align:center">
<b> Sample Statistic </b>
<tr>
<td style="text-align:center">
Mean (<span class="math inline">\(\mu\)</span>)
<td style="text-align:center">
Sample Average (<span class="math inline">\(\bar{x}\)</span>)
<tr>
<td style="text-align:center">
Variance (<span class="math inline">\(\sigma^2\)</span>)
<td style="text-align:center">
Sample Variance (<span class="math inline">\(s_x^2\)</span>)
<tr>
<td style="text-align:center">
Standard Deviation (<span class="math inline">\(\sigma\)</span>)
<td style="text-align:center">
Sample Standard Deviation (<span class="math inline">\(s_x\)</span>)
</table>
<p>Calculating point estimates should lead us to a natural question, one that embodies the field of statistics which aims to quantify uncertainty: <em>What’s the margin of error for this estimate? </em>
This will be the subject of interest in the next two sections.</p>
</div>
<div id="ci" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Confidence Intervals<a href="intro-stat.html#ci" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s imagine that we want to calculate the average gas mileage of American cars on the road today in order to analyze the country’s carbon footprint. It should be clear to the reader that the calculation of the <em>population mean</em> would not be possible. The best we could do is take a large representative sample and calculate the sample average. Again, the next question should be: What is the margin of error for this estimate? If our sample average is 21.1 mpg, could the population mean reasonably be 21.2 mpg? how about 25 mpg? 42 mpg?</p>
<p>To answer this question, we reach for the notion of <em>confidence intervals</em>. A <strong>confidence interval</strong> is an interval that we believe contains the population mean with some degree of confidence. A confidence interval is associated with a <em>confidence level</em>, a percentage, which indicates the strength of our confidence that the population mean is contained in the interval.</p>
<p>It’s an important nuance to remember that the population mean is a fixed number. The source of randomness in our estimation is our sample. When we construct a 95% confidence interval, we are claiming that, upon repetition of the sampling and interval calculation process, we expect 95% of our created intervals to contain the population mean.</p>
<p>To obtain a confidence interval for a mean in R, we can use the <code>t.test()</code> function, as shown below.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="intro-stat.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(ames<span class="sc">$</span>Sale_Price, <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  ames$Sale_Price
## t = 122.5, df = 2929, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  177902.3 183689.9
## sample estimates:
## mean of x 
##  180796.1</code></pre>
<p>We can gather based on the output that our 95% confidence interval for the mean of <code>Sale_Price</code> is [177902.3, 183689.9]. This function also outputs some alternative information that relates to hypothesis testing which we will discuss in Section <a href="intro-stat.html#hypotest">1.4</a>. For now, if we’d like to restrict the output, we can extract the confidence interval by adding <code>$conf.int</code> to our code:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="intro-stat.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(ames<span class="sc">$</span>Sale_Price, <span class="at">conf.level =</span> <span class="fl">0.95</span>)<span class="sc">$</span>conf.int</span></code></pre></div>
<pre><code>## [1] 177902.3 183689.9
## attr(,&quot;conf.level&quot;)
## [1] 0.95</code></pre>
<p>To learn the labels of the various pieces of output, you can list them with the <code>ls()</code> function, or by saving the output as an object (below, <code>results</code> is the object that stores the output) and exploring it in your environment (upper right panel in RStudio):</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="intro-stat.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ls</span>(<span class="fu">t.test</span>(ames<span class="sc">$</span>Sale_Price, <span class="at">conf.level =</span> <span class="fl">0.95</span>))</span></code></pre></div>
<pre><code>##  [1] &quot;alternative&quot; &quot;conf.int&quot;    &quot;data.name&quot;  
##  [4] &quot;estimate&quot;    &quot;method&quot;      &quot;null.value&quot; 
##  [7] &quot;p.value&quot;     &quot;parameter&quot;   &quot;statistic&quot;  
## [10] &quot;stderr&quot;</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="intro-stat.html#cb34-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">t.test</span>(ames<span class="sc">$</span>Sale_Price, <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
</div>
<div id="hypotest" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Hypothesis Testing<a href="intro-stat.html#hypotest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A confidence interval can help us test a hypothesis about the population mean. A <strong>hypothesis</strong> is merely a statement that we wish to investigate scientifically through the process of statistical inference. In Section <a href="intro-stat.html#ci">1.3</a> we proposed some potential hypotheses in the form of questions: If the sample average gas mileage is 21.1, is it possible that the population mean is 21.2? How about 42? The statistical <strong>hypothesis test</strong> can help us answer these questions.</p>
<p>To conduct a hypothesis test, we make an initial assumption. This initial assumption is called the <strong>null hypothesis</strong> and typically denoted as <span class="math inline">\(H_0\)</span>. We then analyze the data and determine whether our observations are likely, given our assumption of the null hypothesis. If we determine that our observed data was unlikely <em>enough</em> (beyond some threshold of confidence that we set before hand - or beyond a “reasonable doubt” in the justice system) then we <em>reject</em> our initial assumption in favor of the opposite statement, known as the <strong>alternative hypothesis</strong> denoted <span class="math inline">\(H_a\)</span>. The confidence threshold or <strong>confidence level</strong> that we use to determine how much evidence is required to reject the null hypothesis is a proportion, <span class="math inline">\(\alpha\)</span>, which specifies how often we’re willing to incorrectly reject the null hypothesis. Remember, in applied statistics there are no proofs. Every decision we make comes with some degree of uncertainty. <span class="math inline">\(\alpha\)</span> quantifies our allowance for that uncertainty. In statistical textbooks of years past, <span class="math inline">\(\alpha = 0.05\)</span> was the norm. Later in this text we will propose much smaller values for <span class="math inline">\(\alpha\)</span> depending on your sample size.</p>
<p>In order to quantify how unlikely it was that we observed a statistic as extreme or more extreme than we did, we calculate a <strong>p-value</strong>. The p-value is the area under the <strong>null distribution</strong> that represents the probability that we observed something as extreme or more extreme than we did (assuming the truth of the null hypothesis). If our p-value is less than our confidence level, <span class="math inline">\(\alpha\)</span>, we have enough evidence to reject the null hypothesis in favor of the alternative.</p>
<p>Let’s take an example and actually <em>create</em> a null distribution. Suppose we flip a fair coin, having equal probability of landing on heads or tails. We can actually simulate this experience with code! The following line of code does just that. Go ahead and run it a few times until you observe a coin flip of each type.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="intro-stat.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&#39;Heads&#39;</span>,<span class="st">&#39;Tails&#39;</span>), <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Heads&quot;</code></pre>
<p>Now, let’s suppose we do that <em>many</em> times and count the number of times we observe one outcome, say <code>Heads</code>. This can be done by sampling the values directly into a vector. Let <code>n</code> be the number of coin tosses.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="intro-stat.html#cb37-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">100</span></span>
<span id="cb37-2"><a href="intro-stat.html#cb37-2" aria-hidden="true" tabindex="-1"></a>outcomes <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&#39;Heads&#39;</span>,<span class="st">&#39;Tails&#39;</span>), n, <span class="at">replace=</span>T)</span></code></pre></div>
<p>We can count the number of <code>Heads</code> we obtained as follows:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="intro-stat.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(outcomes<span class="sc">==</span><span class="st">&quot;Heads&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 58</code></pre>
<p>Every time you run the lines of code above you will find a different set of coin flips and a varying number of <code>Heads</code>; <em>however</em> the number of <code>Heads</code> will revolve around 50, because that is what we’d expect for a fair coin whose probability of <code>Heads</code> is 50% (Indeed, this simulates a draw from a binomial distribution with n=100 and p=0.5; the expected value of that distribution is <span class="math inline">\(np=50\)</span> and the variance is <span class="math inline">\(np(1-p)=25\)</span>).</p>
<p>Thus, if were to do the above experiment thousands of times, we could map out a distribution of how many <code>Heads</code> one might reasonably receive by tossing a fair coin 100 times. Let’s do that, using a <code>for</code> loop. Let <code>T</code> be the number of simulated experiments (each experiment tosses the coin 100 times), and let <code>number_heads</code> be a vector that stores the number of heads for each experiment. We can initialize <code>number_heads</code> with an empty vector. Notice that our loop overwrites the coin toss data in each step, after recording the number of heads.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="intro-stat.html#cb40-1" aria-hidden="true" tabindex="-1"></a>T<span class="ot">=</span><span class="dv">10000</span></span>
<span id="cb40-2"><a href="intro-stat.html#cb40-2" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">100</span></span>
<span id="cb40-3"><a href="intro-stat.html#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11</span>)</span>
<span id="cb40-4"><a href="intro-stat.html#cb40-4" aria-hidden="true" tabindex="-1"></a>number_heads <span class="ot">=</span> <span class="fu">vector</span>()</span>
<span id="cb40-5"><a href="intro-stat.html#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>T){</span>
<span id="cb40-6"><a href="intro-stat.html#cb40-6" aria-hidden="true" tabindex="-1"></a>outcomes <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&#39;Heads&#39;</span>,<span class="st">&#39;Tails&#39;</span>), n, <span class="at">replace=</span>T)</span>
<span id="cb40-7"><a href="intro-stat.html#cb40-7" aria-hidden="true" tabindex="-1"></a>number_heads[i] <span class="ot">=</span> <span class="fu">sum</span>(outcomes<span class="sc">==</span><span class="st">&quot;Heads&quot;</span>)</span>
<span id="cb40-8"><a href="intro-stat.html#cb40-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb40-9"><a href="intro-stat.html#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="intro-stat.html#cb40-10" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(number_heads)</span>
<span id="cb40-11"><a href="intro-stat.html#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="intro-stat.html#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> df) <span class="sc">+</span></span>
<span id="cb40-13"><a href="intro-stat.html#cb40-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> number_heads)) <span class="sc">+</span> </span>
<span id="cb40-14"><a href="intro-stat.html#cb40-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Number of heads in 100 tosses&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cointoss"></span>
<img src="bookdownproj_files/figure-html/cointoss-1.png" alt="Null Distribution: Number of heads for fair coin tossed 100 times " width="672" />
<p class="caption">
Figure 1.15: Null Distribution: Number of heads for fair coin tossed 100 times
</p>
</div>
<p>Figure <a href="intro-stat.html#fig:cointoss">1.15</a> represents our null distribution of the number of heads from a fair coin tossed 100 times. What are the minimum and maximum values of this observed distribution?</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="intro-stat.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(df<span class="sc">$</span>number_heads)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   33.00   47.00   50.00   49.99   53.00   71.00</code></pre>
<hr />
<p><strong>Example</strong></p>
<p>Suppose now we obtain a new coin from a friend and our hypothesis is that it “feels unfair”. We decide that we want to be 99% confident before we accuse our friend of cheating, so we conduct a hypothesis test. Our null hypothesis must generate a known distribution to which we can compare. Thus our null hypothesis is that the coin is fair:
<span class="math display">\[H_0 = \text{The coin is fair:}\quad P(Heads) = 0.5\]</span>
Our alternative hypothesis is the opposite of this:
<span class="math display">\[H_0 = \text{The coin is not fair:}\quad P(Heads) \neq 0.5\]</span>
Suppose we flip the coin 100 times and count 65 heads. How likely is it that we would have obtained a result as extreme or more extreme than this if the coin was fair? Here we introduce the notion of a <strong>two-tailed hypothesis test</strong>. Since our hypothesis is that the coin is simply unfair, we want to know how likely it is that we obtained a result <em>so different from 50</em>. This is quantified by the <em>absolute</em> difference between what we observed and what we expected. Thus, when considering our null distribution, we want to look at the probability we’d obtain something greater than or equal to 65 (<span class="math inline">\(=50+15\)</span>) heads, <em>or</em> less than or equal to 35 (<span class="math inline">\(=50-15\)</span>) heads.</p>
Let’s take a look at this graphically through our simulated data:
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cointossht"></span>
<img src="bookdownproj_files/figure-html/cointossht-1.png" alt="Null Distribution: Number of heads for fair coin tossed 100 times " width="672" />
<p class="caption">
Figure 1.16: Null Distribution: Number of heads for fair coin tossed 100 times
</p>
</div>
<p>We can use this simulated distribution to estimate the p-value associated with obtaining 65 heads (the red area highlighted in Figure <a href="intro-stat.html#fig:cointossht">1.16</a>. We’d simply calculate the proportion of times we observed values equal to or more extreme than 65 - this is the very definition of a p-value. In the following line of code, <code>|</code> represents the logical “or” operator.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="intro-stat.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(number_heads<span class="sc">&gt;=</span><span class="dv">65</span> <span class="sc">|</span> number_heads<span class="sc">&lt;=</span><span class="dv">35</span>)<span class="sc">/</span>T</span></code></pre></div>
<pre><code>## [1] 0.0041</code></pre>
<p><strong>Conclusion</strong>: We said at the outset that we wanted to be 99% certain of our claim before we accused our friend of cheating. Based on our simulations, there is a 0.4% chance that we’d obtain the result we did, or something more extreme, if the coin was fair. Therefore, we have no choice but to <em>reject our null hypothesis in favor of the alternative</em>. Our friend has some explaining to do!</p>
<p>Before we move on, we can compare the simulated result we just developed to one based on a theoretical distribution. This can be done using the <code>prop.test()</code> function to test a proportion. The formal test confirms our conclusion.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="intro-stat.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop.test</span>(<span class="dv">65</span>, <span class="dv">100</span>, <span class="at">p =</span> <span class="fl">0.5</span>,</span>
<span id="cb45-2"><a href="intro-stat.html#cb45-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">alternative =</span> <span class="fu">c</span>(<span class="st">&quot;two.sided&quot;</span>),</span>
<span id="cb45-3"><a href="intro-stat.html#cb45-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">conf.level =</span> <span class="fl">0.99</span>)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test with continuity
##  correction
## 
## data:  65 out of 100
## X-squared = 8.41, df = 1, p-value = 0.003732
## alternative hypothesis: true p is not equal to 0.5
## 99 percent confidence interval:
##  0.5162768 0.7643236
## sample estimates:
##    p 
## 0.65</code></pre>
<hr />
The nice thing about a simulation study like the one above is that it allows the user to explore how changes in the underlying procedure might affect the outcome. We’ll next consider two pieces that of the simulation study and how they affect the p-value: the <em>sample size</em> (the number of coin flips) and the <em>effect size</em> (the observed deviation from 50% heads).
<ol>
<li>
What happens if we increase/decrease the number of coin flips in our experiment, but keep the effect size the same, fixed at 65% heads? If we only flipped the coin 10 times, would 6-7 heads be improbable to witness from a fair coin? If we flipped the coin 1000 times, would 650 heads be <em>more</em> or <em>less</em> improbable than that same ratio in 10 tosses? In other words, which of these situations would entail a smaller p-value? We hope that the reader now has some intuition to answer this question. If not, we encourage them to answer it by altering the value of <code>n</code> in the simulation code, and seeing how the changes affect the distribution of the null hypothesis.
<li>
<p>What happens if we fix the sample size at 100 tosses and decrease the effect size from 65 heads to 60 heads? We’ve already generated the data to answer this question - our p-value would <em>increase</em> because it would be <em>more</em> probable to obtain a smaller effect size from a fair coin. On the flip side (pun intended) the p-value would <em>decrease</em> for a larger effect size.</p>
<div id="onesample" class="section level3 hasAnchor" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> One-Sample T-Test<a href="intro-stat.html#onesample" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we want to test whether the mean of continuous variable is equal to hypothesized value, we can use the <code>t.test()</code> function. The following code tests whether the average sale price of homes from Ames, Iowa over the data time period is $178,000. For now, we’ll use the classic <span class="math inline">\(\alpha=0.05\)</span> as our confidence level. If we have enough evidence to reject this null hypothesis, we will conclude that the mean sale price is either lower or higher for a two-tailed test (the default):</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="intro-stat.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(ames<span class="sc">$</span>Sale_Price, <span class="at">mu =</span> <span class="dv">178000</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  ames$Sale_Price
## t = 1.8945, df = 2929, p-value = 0.05825
## alternative hypothesis: true mean is not equal to 178000
## 95 percent confidence interval:
##  177902.3 183689.9
## sample estimates:
## mean of x 
##  180796.1</code></pre>
<p>Because our <em>p-value is greater than our alpha</em> level of 0.05, we <em>fail to reject</em> the null hypothesis. We do not quite have sufficient evidence to say the mean is different from 178,000.</p>
<p>If we’re instead interested in testing whether the <code>Sale_Price</code> is <em>higher</em> than $178,000, we can specify this in the <code>alternative=</code> option.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="intro-stat.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(ames<span class="sc">$</span>Sale_Price, <span class="at">mu =</span> <span class="dv">178000</span>, <span class="at">alternative =</span> <span class="st">&#39;greater&#39;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  ames$Sale_Price
## t = 1.8945, df = 2929, p-value = 0.02913
## alternative hypothesis: true mean is greater than 178000
## 95 percent confidence interval:
##  178367.7      Inf
## sample estimates:
## mean of x 
##  180796.1</code></pre>
<p>In this second test, we see that we actually <em>do have enough evidence</em> to claim that the true mean is greater than $178,000 at the <span class="math inline">\(\alpha=0.05\)</span> level.</p>
</div>
</div>
<div id="two-sample-t-tests" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Two-Sample t-tests<a href="intro-stat.html#two-sample-t-tests" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If we have a hypothesis about a difference in the means of two groups of observations, a <strong>two-sample t-test</strong> can tell us whether that difference is statistically significant. By <em>statistically significant</em>, we mean the observed difference in sample means is greater than what we would expect to find if the population means were truly equal. In other words, statistical significance is a phrase that describes when our p-value falls below our confidence level, <span class="math inline">\(\alpha\)</span>. Typically, the groups of interest are formed by levels of a binary variable, and the t-test is a way of testing whether there is a relationship between that binary variable and the continuous variable.</p>
To conduct a two-sample t-test, our data should satisfy 3 fundamental assumptions:
<ol>
<li>
The observations are independent
<li>
The data from each group is normally distributed
<li>
The variances for each group are equal
</ol>
<p>If our data does not satisfy these assumptions, we must adapt our test to the situation. If the <span class="math inline">\(3^{rd}\)</span> assumption of equal variances is not met, we simply add the option <code>var.equal=F</code> to the <code>t.test()</code> function to use the Welch or Satterthwaite approximation to degrees of freedom (it’s becoming increasingly common for practitioners to use this option even when variances are equal).</p>
<p>If the <span class="math inline">\(2^{nd}\)</span> assumption is not met, one must opt for a <em>nonparametric</em> test like the Mann-Whitney-U test (also called the Mann–Whitney–Wilcoxon or the Wilcoxon rank-sum test).</p>
<p>The <span class="math inline">\(1^{st}\)</span> assumption is not easily checked unless the data is generated over time (time-series) and is instead generally implied by careful data collect and the application of domain expertise.</p>
<div id="testnorm" class="section level3 hasAnchor" number="1.5.1">
<h3><span class="header-section-number">1.5.1</span> Testing Normality of Groups<a href="intro-stat.html#testnorm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The t-test is robust to deviations from normality, thus we can test the normality assumption either graphically or through formal statistical tests. The best graphical test of normality is a QQ-Plot, though histograms are often used as well. We saw in Figures <a href="intro-stat.html#fig:qqplot">1.10</a> and <a href="intro-stat.html#fig:histogram">1.2</a> that the distribution of <code>Sale_Price</code> was not perfectly normal, however the deviations from normality were not egregious. In Figure <a href="intro-stat.html#fig:qqplotcentralair">1.17</a> we again examine the normality of Sale Price, this time for each value of <code>Central_Air</code>:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="intro-stat.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames, <span class="fu">aes</span>(<span class="at">sample =</span> Sale_Price, <span class="at">color =</span> Central_Air)) <span class="sc">+</span></span>
<span id="cb51-2"><a href="intro-stat.html#cb51-2" aria-hidden="true" tabindex="-1"></a>     <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb51-3"><a href="intro-stat.html#cb51-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qqplotcentralair"></span>
<img src="bookdownproj_files/figure-html/qqplotcentralair-1.png" alt="QQ-Plot: Quantiles of Sale_Price vs. quantiles of a theoretical normal distribution with same mean and standard deviation, for each level of Central_Air. Conclusion: Sale_Price is _not_ normally distributed for Central_Air='Yes' and is _more_ normally distributed for Central_Air = 'No'." width="672" />
<p class="caption">
Figure 1.17: QQ-Plot: Quantiles of Sale_Price vs. quantiles of a theoretical normal distribution with same mean and standard deviation, for each level of Central_Air. Conclusion: Sale_Price is <em>not</em> normally distributed for Central_Air=‘Yes’ and is <em>more</em> normally distributed for Central_Air = ‘No’.
</p>
</div>
<p>For formal tests of normality, we most often use the Shapiro-Wilk test, although many such formal tests exist, each with their own advantages. All of these tests have the null hypothesis of normality:
<span class="math display">\[H_0: \text{ the data is normally distributed}\]</span>
<span class="math display">\[H_a: \text{ the data is NOT normally distributed}\]</span>
We conduct formal tests as follows:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="intro-stat.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(ames<span class="sc">$</span>Sale_Price[ames<span class="sc">$</span>Central_Air<span class="sc">==</span><span class="st">&#39;Y&#39;</span>])</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  ames$Sale_Price[ames$Central_Air == &quot;Y&quot;]
## W = 0.86295, p-value &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="intro-stat.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(ames<span class="sc">$</span>Sale_Price[ames<span class="sc">$</span>Central_Air<span class="sc">==</span><span class="st">&#39;N&#39;</span>])</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  ames$Sale_Price[ames$Central_Air == &quot;N&quot;]
## W = 0.95315, p-value = 4.739e-06</code></pre>
<p>The formal test rejects the null hypotheses of normality and confirms what we saw in our visual analysis.</p>
<p>While this attribute is, indeed, NOT normally distributed, it is important to note that <strong>the t-test is robust to deviations from normality, provided the underlying distribution is unimodal, relatively symmetric and not <em>severely</em> skewed/kurtotic. </strong>
For the sake of illustration, we will proceed in this example under the assumption of normality, though a non-parametric approach will also be demonstrated to confirm our analysis in Section <a href="intro-stat.html#wilcoxon">1.5.4</a>.</p>
</div>
<div id="ftest" class="section level3 hasAnchor" number="1.5.2">
<h3><span class="header-section-number">1.5.2</span> Testing Equality of Variances<a href="intro-stat.html#ftest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can conduct a formal test to confirm that the <span class="math inline">\(3^{rd}\)</span> assumption is met. This test for equal variances is known as an F-Test. The null hypothesis is that the variances are equal, the alternative being that they are not:
<span class="math display">\[H_0: \sigma_1^2 = \sigma_2^2\]</span>
<span class="math display">\[H_a: \sigma_1^2 \neq \sigma_2^2\]</span></p>
<p>The F-Test is invoked with the <code>var.test</code> function, which takes as input a <code>formula</code>. A formula is an R object most often created using the <code>~</code> operator, for example <code>y ~ x + z</code>, interpreted as a specification that the response <code>y</code> is to be predicted with the inputs <code>x</code> and <code>z</code>. For our present discussion on two-sample t-tests, we might think of predicting our continuous attribute with our binary attribute, provided the means are different between the two groups.</p>
<p>The following code checks whether the distributions of Sale_Price for houses with and without central air have the same variance.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="intro-stat.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var.test</span>(Sale_Price <span class="sc">~</span> Central_Air, <span class="at">data =</span> ames)</span></code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  Sale_Price by Central_Air
## F = 0.2258, num df = 195, denom df = 2733,
## p-value &lt; 2.2e-16
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.1854873 0.2800271
## sample estimates:
## ratio of variances 
##          0.2257977</code></pre>
<p>They do not. Thus, we must opt for the <code>var.equal=FALSE</code> option in the <code>t.test()</code> procedure.</p>
</div>
<div id="tsttest" class="section level3 hasAnchor" number="1.5.3">
<h3><span class="header-section-number">1.5.3</span> Testing Equality of Means<a href="intro-stat.html#tsttest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Assuming the first two assumptions are met, the two-sample t-test is performed by including a binary grouping variable with into the <code>t.test()</code> function. Below we test whether the mean sales price is different for houses with and without <code>Central_Air</code>, and we include the <code>var.equal=FALSE</code> option because we determined that the variances of the two groups were unequal in Section <a href="intro-stat.html#ftest">1.5.2</a>. The null hypothesis for the t-test is that the means of the two groups are equal:
<span class="math display">\[H_0: \mu_1 = \mu_2\]</span>
<span class="math display">\[H_a: \mu_1 \neq \mu_2\]</span></p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="intro-stat.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(Sale_Price <span class="sc">~</span> Central_Air, <span class="at">data =</span> ames, <span class="at">var.equal =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Sale_Price by Central_Air
## t = -27.433, df = 336.06, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means between group N and group Y is not equal to 0
## 95 percent confidence interval:
##  -90625.69 -78498.92
## sample estimates:
## mean in group N mean in group Y 
##        101890.5        186452.8</code></pre>
<p>Our final conclusion from the t-test is the <em>rejection of the null hypothesis</em> and the conclusion that <em>houses with and without central air should be expected to sell for different prices. </em></p>
</div>
<div id="wilcoxon" class="section level3 hasAnchor" number="1.5.4">
<h3><span class="header-section-number">1.5.4</span> Mann-Whitney-Wilcoxon Test<a href="intro-stat.html#wilcoxon" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As we pointed out in Section <a href="intro-stat.html#testnorm">1.5.1</a>, the distribution of <code>Sale_Price</code> was not precisely normal. The most principled way to proceed in this case would be with a non-parametric test. The Mann-Whitney-Wilcoxon test is not identical to the t-test in its null and alternative hypotheses, but it aims to answer the same question about an association between the binary attribute and the continuous attribute.</p>
<p>The null and alternative hypotheses for this test are typically defined as follows, so long as the <em>is</em> identically distributed (having the same <em>shape</em> and variance):
<span class="math display">\[H_0: \text{ the medians of the two groups are equal }  \]</span>
<span class="math display">\[H_a: \text{ the medians of the two groups are NOT equal }   \]</span>
If those identical distributions are also symmetric, then Mann-Whitney-Wilcoxon can be interpretted as testing for a difference in means. When the data is not identically distributed, or when the distributions are not symmetric, Mann-Whitney-Wilcoxon is a test of <strong>dominance</strong> between distributions. <strong>Distributional dominance</strong> is the notion that one group’s distribution is located at larger values than another, probabilistically speaking. Formally, a random variable A has dominance over random variable B if <span class="math inline">\(P(A x) \geq P(B\geq x)\)</span> for all <span class="math inline">\(x\)</span>, and for some <span class="math inline">\(x\)</span>, <span class="math inline">\(P(A\geq x) &gt; P(B\geq x)\)</span>.</p>
<p>We summarize this information in the following table:</p>
<table style="width:auto; margin-left: auto; margin-right: auto;">
<tr>
<td>
Conditions
<td>
Interpretation of Significant <br> Mann-Whitney-Wilcoxon Test
<tr>
<td>
Group distributions are identical in shape,<br> variance, and symmetric
<td>
Difference in means
<tr>
<td>
Group distributions are identical in shape,<br> variance, but not symmetric
<td>
Difference in medians
<tr>
<td>
Group distributions are identical in shape,<br> variance, but not symmetric
<td>
Difference in location. <br> (distributional dominance)
</tr>
</table>
<p>To perform this test, we use the <code>wilcox.test()</code> function, whose inputs are identical to the <code>t.test()</code> function.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="intro-stat.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(Sale_Price <span class="sc">~</span> Central_Air, <span class="at">data =</span> ames)</span></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity
##  correction
## 
## data:  Sale_Price by Central_Air
## W = 63164, p-value &lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>Thus, we make the same conclusion with our non-parametric test. Houses with and without central air should be expected to sell for different prices.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="slr.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/IAA-Faculty/statistical_foundations.git/edit/master/01-introduction_statistics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/IAA-Faculty/statistical_foundations.git/blob/master/01-introduction_statistics.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"toc": null
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
