<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Exploratory Data Analysis (EDA) | Statistical Foundations</title>
  <meta name="description" content="Chapter 1 Exploratory Data Analysis (EDA) | Statistical Foundations" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Exploratory Data Analysis (EDA) | Statistical Foundations" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="IAA-Faculty/statistical_foundations" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Exploratory Data Analysis (EDA) | Statistical Foundations" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="slr.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a style="font-weight:bold" href="https://github.com/IAA-Faculty/statistical_foundations/">Statistical Foundations</a>
<img src="./img/iaaicon.png" alt="IAA"  class="center"</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-authors"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>1</b> Exploratory Data Analysis (EDA)</a>
<ul>
<li class="chapter" data-level="1.1" data-path="eda.html"><a href="eda.html#vartypes"><i class="fa fa-check"></i><b>1.1</b> Types of Variables</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="eda.html"><a href="eda.html#nominal-variables"><i class="fa fa-check"></i><b>1.1.1</b> Nominal Variables</a></li>
<li class="chapter" data-level="1.1.2" data-path="eda.html"><a href="eda.html#interval-variables"><i class="fa fa-check"></i><b>1.1.2</b> Interval Variables</a></li>
<li class="chapter" data-level="1.1.3" data-path="eda.html"><a href="eda.html#ordinal-variables"><i class="fa fa-check"></i><b>1.1.3</b> Ordinal Variables</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="eda.html"><a href="eda.html#honest-assessment"><i class="fa fa-check"></i><b>1.2</b> Honest Assessment</a></li>
<li class="chapter" data-level="1.3" data-path="eda.html"><a href="eda.html#distributions"><i class="fa fa-check"></i><b>1.3</b> Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="eda.html"><a href="eda.html#location"><i class="fa fa-check"></i>Location</a></li>
<li class="chapter" data-level="" data-path="eda.html"><a href="eda.html#spread"><i class="fa fa-check"></i>Spread</a></li>
<li class="chapter" data-level="" data-path="eda.html"><a href="eda.html#shape"><i class="fa fa-check"></i>Shape</a></li>
<li class="chapter" data-level="" data-path="eda.html"><a href="eda.html#summary-functions"><i class="fa fa-check"></i>Summary Functions</a></li>
<li class="chapter" data-level="1.3.1" data-path="eda.html"><a href="eda.html#normal-distribution"><i class="fa fa-check"></i><b>1.3.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="eda.html"><a href="eda.html#graphical-displays-of-distributions"><i class="fa fa-check"></i>Graphical Displays of Distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="eda.html"><a href="eda.html#confidence-intervals"><i class="fa fa-check"></i><b>1.4</b> Confidence Intervals</a></li>
<li class="chapter" data-level="1.5" data-path="eda.html"><a href="eda.html#hypothesis-testing"><i class="fa fa-check"></i><b>1.5</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="1.6" data-path="eda.html"><a href="eda.html#two-sample-t-tests"><i class="fa fa-check"></i><b>1.6</b> Two-Sample t-tests</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="slr.html"><a href="slr.html"><i class="fa fa-check"></i><b>2</b> Introduction to ANOVA and Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="slr.html"><a href="slr.html#explanation-vs.-prediction"><i class="fa fa-check"></i><b>2.1</b> Explanation vs. Prediction</a></li>
<li class="chapter" data-level="2.2" data-path="slr.html"><a href="slr.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>2.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="2.3" data-path="slr.html"><a href="slr.html#one-way-anova"><i class="fa fa-check"></i><b>2.3</b> One-Way ANOVA</a></li>
<li class="chapter" data-level="2.4" data-path="slr.html"><a href="slr.html#anova-post-hoc-testing"><i class="fa fa-check"></i><b>2.4</b> ANOVA Post-hoc Testing</a></li>
<li class="chapter" data-level="2.5" data-path="slr.html"><a href="slr.html#pearson-correlation"><i class="fa fa-check"></i><b>2.5</b> Pearson Correlation</a></li>
<li class="chapter" data-level="2.6" data-path="slr.html"><a href="slr.html#simple-linear-regression"><i class="fa fa-check"></i><b>2.6</b> Simple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="complex-anova-and-multiple-linear-regression.html"><a href="complex-anova-and-multiple-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Complex ANOVA and Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="complex-anova-and-multiple-linear-regression.html"><a href="complex-anova-and-multiple-linear-regression.html#two-way-anova"><i class="fa fa-check"></i><b>3.1</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="3.2" data-path="complex-anova-and-multiple-linear-regression.html"><a href="complex-anova-and-multiple-linear-regression.html#two-way-anova-with-interactions"><i class="fa fa-check"></i><b>3.2</b> Two-Way ANOVA with Interactions</a></li>
<li class="chapter" data-level="3.3" data-path="complex-anova-and-multiple-linear-regression.html"><a href="complex-anova-and-multiple-linear-regression.html#randomized-block-design"><i class="fa fa-check"></i><b>3.3</b> Randomized Block Design</a></li>
<li class="chapter" data-level="3.4" data-path="complex-anova-and-multiple-linear-regression.html"><a href="complex-anova-and-multiple-linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.4</b> Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-building-scoring-for-prediction.html"><a href="model-building-scoring-for-prediction.html"><i class="fa fa-check"></i><b>4</b> Model Building &amp; Scoring for Prediction</a>
<ul>
<li class="chapter" data-level="4.1" data-path="model-building-scoring-for-prediction.html"><a href="model-building-scoring-for-prediction.html#model-complexity"><i class="fa fa-check"></i><b>4.1</b> Model Complexity</a></li>
<li class="chapter" data-level="4.2" data-path="model-building-scoring-for-prediction.html"><a href="model-building-scoring-for-prediction.html#regularized-regression"><i class="fa fa-check"></i><b>4.2</b> Regularized Regression</a></li>
<li class="chapter" data-level="4.3" data-path="model-building-scoring-for-prediction.html"><a href="model-building-scoring-for-prediction.html#modeling-scoring"><i class="fa fa-check"></i><b>4.3</b> Modeling Scoring</a></li>
<li class="chapter" data-level="4.4" data-path="model-building-scoring-for-prediction.html"><a href="model-building-scoring-for-prediction.html#model-metrics"><i class="fa fa-check"></i><b>4.4</b> Model Metrics</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>5</b> Model Selection</a>
<ul>
<li class="chapter" data-level="5.1" data-path="model-selection.html"><a href="model-selection.html#selection-criteria"><i class="fa fa-check"></i><b>5.1</b> Selection Criteria</a></li>
<li class="chapter" data-level="5.2" data-path="model-selection.html"><a href="model-selection.html#stepwise-selection"><i class="fa fa-check"></i><b>5.2</b> Stepwise Selection</a>
<ul>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="model-selection.html#forward"><i class="fa fa-check"></i>Forward</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="model-selection.html#backward"><i class="fa fa-check"></i>Backward</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="model-selection.html#stepwise"><i class="fa fa-check"></i>Stepwise</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="model-selection.html#lasso"><i class="fa fa-check"></i>LASSO</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-selection.html"><a href="model-selection.html#significance-levels"><i class="fa fa-check"></i><b>5.3</b> Significance Levels</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="diagnostics.html"><a href="diagnostics.html"><i class="fa fa-check"></i><b>6</b> Diagnostics</a>
<ul>
<li class="chapter" data-level="6.1" data-path="diagnostics.html"><a href="diagnostics.html#examining-residuals"><i class="fa fa-check"></i><b>6.1</b> Examining Residuals</a></li>
<li class="chapter" data-level="6.2" data-path="diagnostics.html"><a href="diagnostics.html#misspecified-model"><i class="fa fa-check"></i><b>6.2</b> Misspecified Model</a></li>
<li class="chapter" data-level="6.3" data-path="diagnostics.html"><a href="diagnostics.html#constant-variance"><i class="fa fa-check"></i><b>6.3</b> Constant Variance</a></li>
<li class="chapter" data-level="6.4" data-path="diagnostics.html"><a href="diagnostics.html#normality"><i class="fa fa-check"></i><b>6.4</b> Normality</a></li>
<li class="chapter" data-level="6.5" data-path="diagnostics.html"><a href="diagnostics.html#correlated-errors"><i class="fa fa-check"></i><b>6.5</b> Correlated Errors</a></li>
<li class="chapter" data-level="6.6" data-path="diagnostics.html"><a href="diagnostics.html#influential-observations-and-outliers"><i class="fa fa-check"></i><b>6.6</b> Influential Observations and Outliers</a></li>
<li class="chapter" data-level="6.7" data-path="diagnostics.html"><a href="diagnostics.html#multicollinearity"><i class="fa fa-check"></i><b>6.7</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html"><i class="fa fa-check"></i><b>7</b> Categorical Data Analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#describing-categorical-data"><i class="fa fa-check"></i><b>7.1</b> Describing Categorical Data</a></li>
<li class="chapter" data-level="7.2" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#tests-of-association"><i class="fa fa-check"></i><b>7.2</b> Tests of Association</a></li>
<li class="chapter" data-level="7.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#measures-of-association"><i class="fa fa-check"></i><b>7.3</b> Measures of Association</a></li>
<li class="chapter" data-level="7.4" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#introduction-to-logistic-regression"><i class="fa fa-check"></i><b>7.4</b> Introduction to Logistic Regression</a></li>
<li class="chapter" data-level="7.5" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#adding-categorical-variables-and-interactions"><i class="fa fa-check"></i><b>7.5</b> Adding Categorical Variables and Interactions</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Foundations</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="eda" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Exploratory Data Analysis (EDA)</h1>
The crucial first step to any data science problem is exploratory data analysis (EDA). Before you attempt to run any models, or jump towards any formal statistical analysis, you must <strong><em>explore your data</em></strong>. Many unexpected frustrations arise when exploratory analysis is overlooked; knowing your data is critical to your ability to make necessary assumptions about it. This preliminary analysis will help inform our decisions for data manipulation, give us a base-level understanding of our variables and the relationships between them, and help determine which statistical analyses might be appropriate for the questions we are trying to answer. Some of the questions we aim to answer through exploratory analysis are:
<ul>
<li>
What kind of variables to you have?
<ul>
<li>
Continuous
<li>
Nominal
<li>
Ordinal
</ul>
<li>
How are the attributes stored?
<ul>
<li>
Strings
<li>
Integers
<li>
Floats/Numeric
<li>
Dates
</ul>
<li>
What do their distributions look like?
<ul>
<li>
Center/Location
<li>
Spread
<li>
Shape
</ul>
<li>
Are there any anomolies?
<ul>
<li>
Outliers
<li>
Leverage points
<li>
Missing values
<li>
Low-frequency categories
</ul>
</ul>
<p>We will maintain an example data set throughout this text to demonstrate the various tools and techniques being discussed. It is a real-estate data set that contains the <code>sale_price</code> and physical attributes of nearly 3,000 homes in Ames, Iowa in the early 2000s. To access this data, we first install the <code>AmesHousing</code> package, add it to our library and create the nicely formatted data with the <code>make_ames()</code> function.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="eda.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;AmesHousing&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="eda.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AmesHousing)</span>
<span id="cb2-2"><a href="eda.html#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="eda.html#cb2-3" aria-hidden="true" tabindex="-1"></a>ames <span class="ot">&lt;-</span> <span class="fu">make_ames</span>() </span>
<span id="cb2-4"><a href="eda.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(ames)</span></code></pre></div>
<div id="vartypes" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Types of Variables</h2>
<p>The columns of a data set are referred to by a number of <strong>equivalent terms</strong>:</p>
</ul>
<li>
Variables
<li>
Features
<li>
Attributes
<li>
Predictors/Targets
<li>
Factors
<li>
Inputs/Outputs
</ul>
<p>This book may use any of these words interchangeably to refer to a quality or quantity of interest in our data.</p>
<div id="nominal-variables" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Nominal Variables</h3>
<p>A <strong>nominal</strong> or <strong>categorical variable</strong> is a <em>quality of interest</em> whose values have no logical ordering. Color (“blue”, “red”, “green”…), ethnicity (“African-American”, “Asian”, “Caucasian”,…), and style of house (“ranch”, “two-story”, “duplex”, …) are all examples of nominal attributes. The categories or values that these variables can take on - those words listed in quotes and parenthesis - are called the <strong>levels</strong> of the variable.</p>
<p>In modeling, nominal attributes are commonly transformed into <strong>dummy variables</strong>. Dummy variables are binary columns that indicate the presence or absence of a quality. There is more than one way to create dummy variables, and the treatment will be different depending on what type of model you are using. Linear regression models will use either <strong>reference-level</strong> or <strong>effects coding</strong>, whereas other machine learning models are more likely to use one-hot encoding or a variation thereof.</p>
<div id="one-hot-encoding" class="section level4 unnumbered">
<h4>One-hot encoding</h4>
<p>For machine learning applications, it is common to create a binary dummy column for each level of your categorical variable. This is the most intuitive representation of categorical information, answering indicative questions for each level of the variable: <em>“is it blue?”</em>, <em>“is it red?”</em> etc. The table below gives an example of some data, the original nominal variable (color) and the one-hot encoded color information.</p>
<table>
<tr>
<td>
Observation
<td>
Color
<td>
Blue
<td>
Red
<td>
Yellow
<td>
Other
<tr>
<td>
1
<td>
Blue
<td>
1
<td>
0
<td>
0
<td>
0
<tr>
<td>
2
<td>
Yellow
<td>
0
<td>
0
<td>
1
<td>
0
<tr>
<td>
3
<td>
Blue
<td>
1
<td>
0
<td>
0
<td>
0
<tr>
<td>
4
<td>
Red
<td>
0
<td>
1
<td>
0
<td>
0
<tr>
<td>
5
<td>
Red
<td>
0
<td>
1
<td>
0
<td>
0
<tr>
<td>
6
<td>
Blue
<td>
1
<td>
0
<td>
0
<td>
0
<tr>
<td>
7
<td>
Yellow
<td>
0
<td>
0
<td>
1
<td>
0
<tr>
<td>
8
<td>
Other
<td>
0
<td>
0
<td>
0
<td>
1
</table>
<caption>
<span id="tab:onehot">Table 1.1: </span>One-hot dummy variable coding for the categorical attribute <em>color</em>
</caption>
<p>We will demonstrate the creation of this data using some simple random categorical data:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="eda.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">41</span>)</span>
<span id="cb3-2"><a href="eda.html#cb3-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y =</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">2</span>), <span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">1</span>),<span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">0</span>)),</span>
<span id="cb3-3"><a href="eda.html#cb3-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">x1 =</span> <span class="fu">factor</span>(<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>), <span class="at">each =</span> <span class="dv">10</span>)),</span>
<span id="cb3-4"><a href="eda.html#cb3-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">x2 =</span> <span class="fu">factor</span>(<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Z&quot;</span>, <span class="st">&quot;X&quot;</span>, <span class="st">&quot;Y&quot;</span>,<span class="st">&quot;W&quot;</span>,<span class="st">&quot;V&quot;</span>,<span class="st">&quot;U&quot;</span>), <span class="at">each =</span> <span class="dv">5</span>)))</span>
<span id="cb3-5"><a href="eda.html#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">View</span>(data)</span></code></pre></div>
<p>Unlike reference and effects coding, which are typically specified within the <code>lm()</code> function as we will see in Chapter <a href="slr.html#slr">2</a>, one-hot encoding is most quickly achieved through use of the <code>onehot</code> package in R, which first creates an “encoder” to do the job quickly.</p>
<p>The speed of this function has been tested against both the base R <code>model.matrix()</code> function and the <code>dummyVars()</code> function in the <code>caret</code> package and is <em>substantially</em> faster than either.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="eda.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;onehot&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="eda.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(onehot)</span>
<span id="cb5-2"><a href="eda.html#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="eda.html#cb5-3" aria-hidden="true" tabindex="-1"></a>encoder  <span class="ot">=</span> <span class="fu">onehot</span>(data)</span>
<span id="cb5-4"><a href="eda.html#cb5-4" aria-hidden="true" tabindex="-1"></a>dummies <span class="ot">=</span> <span class="fu">predict</span>(encoder,data)</span>
<span id="cb5-5"><a href="eda.html#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dummies)</span></code></pre></div>
<pre><code>##             y x1=A x1=B x1=C x2=U x2=V x2=W x2=X x2=Y x2=Z
## [1,] 1.205632    1    0    0    0    0    0    0    0    1
## [2,] 2.197258    1    0    0    0    0    0    0    0    1
## [3,] 3.001704    1    0    0    0    0    0    0    0    1
## [4,] 3.288825    1    0    0    0    0    0    0    0    1
## [5,] 2.905753    1    0    0    0    0    0    0    0    1
## [6,] 2.493667    1    0    0    0    0    0    1    0    0</code></pre>
</div>
<div id="reference-level-coding" class="section level4 unnumbered">
<h4>Reference-level coding</h4>
<p>Reference-level coding is similar to one-hot encoding except one of the levels of the attribute, called the <strong>reference level</strong>, is omitted. Notice that the 4 dummy columns from Table <a href="eda.html#tab:onehot">1.1</a> collectively form a linearly dependent set; that is, if you know the values of 3 of the 4 dummy variables you can determine the <span class="math inline">\(4^{th}\)</span> with complete certainty. This would be a problem for linear regression, where we assume our input attributes are not linearly dependent as we will discuss in Chapter <a href="slr.html#slr">2</a>.</p>
<p>A reference level of the attribute is often specified by the user to be a particular level worthy of comparison (a baseline), as the regression output will be interpreted in a way that compares each non-reference level to the reference level. If a reference level is not specified by the user, one will be picked by the software by default either using the order in which the levels were encountered in the data, or their alphabetical ordering. Users should check the documentation of the associated function to understand what to expect.</p>
<p>Table <a href="eda.html#tab:refcoding">1.2</a> transforms the one-hot encoding from Table <a href="eda.html#tab:onehot">1.1</a> into reference-level coding with the color “blue” as the reference level. Notice the absence of the column indicating “blue” and how each blue observation exists as a row of zeros.</p>
<table>
<tr>
<td>
Observation
<td>
Color
<td>
Red
<td>
Yellow
<td>
Other
</tr>
<tr>
<td>
1
<td>
Blue
<td>
0
<td>
0
<td>
0
</tr>
<tr>
<td>
2
<td>
Yellow
<td>
0
<td>
1
<td>
0
</tr>
<tr>
<td>
3
<td>
Blue
<td>
0
<td>
0
<td>
0
</tr>
<tr>
<td>
4
<td>
Red
<td>
1
<td>
0
<td>
0
</tr>
<tr>
<td>
5
<td>
Red
<td>
1
<td>
0
<td>
0
</tr>
<tr>
<td>
6
<td>
Blue
<td>
0
<td>
0
<td>
0
</tr>
<tr>
<td>
7
<td>
Yellow
<td>
0
<td>
1
<td>
0
</tr>
<tr>
<td>
8
<td>
Other
<td>
0
<td>
0
<td>
1
</tr>
</table>
<caption>
<span id="tab:refcoding">Table 1.2: </span> Reference-level dummy variable coding for the categorical attribute <em>color</em> and the reference level of “blue”
</caption>
</div>
<div id="effects-coding" class="section level4 unnumbered">
<h4>Effects coding</h4>
<p>Effects coding is useful for obtaining a more general comparative interpretation when you have approximately equal sample sizes across each level of your categorical attribute. Effects coding is designed to allow the user to compare each level to <em>all</em> the other levels. More specifically the mean of each level is compared to the <strong>overall mean</strong> of your data. However, the comparison is actually to the so-called <em>grand mean</em>, which is the mean of the means of each group. When sample sizes are equal, the grand mean and the overall sample mean are equivalent. When sample sizes are <em>not</em> equal, the parameter estimates for effects coding should not be used for interpretation or explanation.</p>
<p>Effects coding still requires a <em>reference level</em>, however the purpose of the reference level is not the same as it was in reference-level coding. Here, the reference level is left out in the sense that no comparison is made between it and the overall mean. Table <a href="eda.html#tab:effcoding">1.3</a> shows our same example with effects coding. Again we notice the absence of the column indicating “blue” but now the reference level receives values of <code>-1</code> rather than <code>0</code> for all 3 dummy columns. We will revisit the interpretation of linear regression coefficients under this coding scheme in Chapter <a href="slr.html#slr">2</a>.</p>
<table>
<tr>
<td>
Observation
<td>
Color
<td>
Red
<td>
Yellow
<td>
Other
<tr>
<td>
1
<td>
Blue
<td>
-1
<td>
-1
<td>
-1
<tr>
<td>
2
<td>
Yellow
<td>
0
<td>
1
<td>
0
<tr>
<td>
3
<td>
Blue
<td>
-1
<td>
-1
<td>
-1
<tr>
<td>
4
<td>
Red
<td>
1
<td>
0
<td>
0
<tr>
<td>
5
<td>
Red
<td>
1
<td>
0
<td>
0
<tr>
<td>
6
<td>
Blue
<td>
-1
<td>
-1
<td>
-1
<tr>
<td>
7
<td>
Yellow
<td>
0
<td>
1
<td>
0
<tr>
<td>
8
<td>
Other
<td>
0
<td>
0
<td>
1
</table>
<caption>
<span id="tab:effcoding">Table 1.3: </span> Effects coding for the categorical attribute <em>color</em> and the reference level of “blue”
</caption>
</div>
</div>
<div id="interval-variables" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Interval Variables</h3>
<p>An interval variable is a <em>quantity of interest</em> on which the mathematical operations of addition, subtraction, multiplication and division can be performed. Time, temperature and age are all examples of interval attributes. To illustrate the definition, note that “15 minutes” divided by “5 minutes” is 3, which indicates that 15 minutes is 3 times as long as 5 minutes. The sensible interpretation of this simple arithmetic sentence demonstrates the nature of interval attributes. One should note that such arithmetic would not make sense in the treatment of nominal variables.</p>
</div>
<div id="ordinal-variables" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Ordinal Variables</h3>
<p><strong>Ordinal variables</strong> are attributes that are qualitative in nature but have some natural ordering. <em>Level of education</em> is a common example, with a level of ‘PhD’ indicating <em>more</em> education than ‘Bachelors’ but lacking a numerical framework to quantify <em>how much more</em>. The treatment of ordinal variables will depend on the application. Survey responses on a Likert scale are also ordinal - a response of 4=“somewhat agree” on a 1-to-5 scale of agreement cannot reliably be said to be twice as enthusiastic as a response of 2=“somewhat disagree”. These are not interval measurements, though they are often treated as such in a trade-off for computational efficiency.</p>
<p><strong>Ordinal variables will either be given some numeric value and treated as interval variables or they will be treated as categorical variables and dummy variables will be created. The choice of solution is up to the analyst.</strong> When numeric values are assigned to ordinal variables, the possibilities are many. For example, consider <em>level of education</em>. The simplest ordinal treatment for such an attribute might be something like:</p>
<table>
<tr>
<td>
Level of Education
<td>
Numeric Value
<tr>
<td>
No H.S. Diploma
<td>
1
<tr>
<td>
H.S. Diploma or GED
<td>
2
<tr>
<td>
Associates or Certificate
<td>
3
<tr>
<td>
Bachelors
<td>
4
<tr>
<td>
Graduate Certificate
<td>
5
<tr>
<td>
Masters
<td>
6
<tr>
<td>
PhD
<td>
7
</table>
<p>While numeric values have been assigned and this data <em>could</em> be used like an interval attribute, it’s important to realize that the notion of a “one-unit-increase” is qualitative in nature rather than quantitative. However, if we’re interested in learning whether there is a <em>linear</em> type of relationship between education and another attribute (meaning as education level increases, the value of another attribute increases or decreases), this would be the path to get us there. However we’re making an assumption in this model that the difference between a H.S. Diploma and an Associates degree (a difference of “1 unit”) is the same as the difference between a Master’s degree and a PhD (also a difference of “1 unit”). These types of assumptions can be flawed, and it is often desirable to develop an alternative system of measurement based either on domain expertise or the target variable of interest. This is the notion behind <strong>optimal scaling</strong> and <strong>target-level encoding</strong>.</p>
<div id="optimal-scaling" class="section level4 unnumbered">
<h4>Optimal Scaling</h4>
</div>
<div id="target-level-encoding" class="section level4 unnumbered">
<h4>Target-level Encoding</h4>
</div>
</div>
</div>
<div id="honest-assessment" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Honest Assessment</h2>
<p>When performing predictive modeling, we <em>always</em> divide our data into subsets for training, validation, and/or final testing. This is a concept that will be revisited several times throughout the introductory curriculum, highlighting its importance to honest assessment of models. There is no single right answer for how this division should occur for every data set - the answer depends on a multitude of factors that are beyond the scope of our present discussion.</p>
<p>Generally speaking, one expects to keep about 70% of the data for model training purposes, and the remaining 30% for validation and testing. These proportions may change depending on the amount and of data available. If one has millions of observations, they can often get away with a much smaller proportion of training data to reduce computation time and increase confidence in validation. If one has substantially fewer observations, it may be necessary to increase the training proportion in order to build a sound model - trading validation confidence for proper training.</p>
<p>Below we demonstrate two techniques for separating the data into just two subsets: training and test. These two subsets will suffice for our analyses in this text. We’ll use 70% of our data for the training set and the remainder for testing.</p>
<p>Since we are taking a random sample, each time you run these functions you will get a different result. This can be difficult for team members who wish to keep their analyses in sync. To avoid that variation of results, we can provide a “seed” to the internal random number generation process, which ensures that the randomly generated output is the same to all who use that seed.</p>
<ol>
<li>
<p>Sampling via the <code>tidyverse</code>. This method requires the use of an id variable. If your data set has a unique identifier built in, you may omit the first line of code (after <code>set.seed()</code>) and use that unique identifier in the third line.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="eda.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb7-2"><a href="eda.html#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="eda.html#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb7-4"><a href="eda.html#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="eda.html#cb7-5" aria-hidden="true" tabindex="-1"></a>ames <span class="ot">&lt;-</span> ames <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">id =</span> <span class="fu">row_number</span>())</span>
<span id="cb7-6"><a href="eda.html#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="eda.html#cb7-7" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> ames <span class="sc">%&gt;%</span> <span class="fu">sample_frac</span>(<span class="fl">0.7</span>)</span>
<span id="cb7-8"><a href="eda.html#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="eda.html#cb7-9" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> <span class="fu">anti_join</span>(ames, train, <span class="at">by =</span> <span class="st">&#39;id&#39;</span>)</span>
<span id="cb7-10"><a href="eda.html#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="eda.html#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(train)</span></code></pre></div>
<pre><code>## [1] 2051   82</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="eda.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(test)</span></code></pre></div>
<pre><code>## [1] 879  82</code></pre>
<li>
<p>Sampling via old-fashioned local indexing. This method creates a logical vector (containing the values <code>TRUE</code> or <code>FALSE</code>) that indicates the training set observations. The opposite vector, <code>!train_obs</code> then indicates the test set. The benefit of this method is the storage of this vector that permanently identifies which observations were placed in the training set.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="eda.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb11-2"><a href="eda.html#cb11-2" aria-hidden="true" tabindex="-1"></a>train_obs <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">c</span>(T,F), <span class="fu">nrow</span>(ames),<span class="at">replace=</span>T, <span class="at">prob =</span> <span class="fu">c</span>(<span class="dv">70</span>,<span class="dv">30</span>))</span>
<span id="cb11-3"><a href="eda.html#cb11-3" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> ames[train_obs, ]</span>
<span id="cb11-4"><a href="eda.html#cb11-4" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> ames[<span class="sc">!</span>train_obs, ]</span>
<span id="cb11-5"><a href="eda.html#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="eda.html#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(train)</span></code></pre></div>
<pre><code>## [1] 2049   82</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="eda.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(test)</span></code></pre></div>
<pre><code>## [1] 881  82</code></pre>
</ol>
<p>It’s important to note that <em>even with the same seed</em>, these two methods will not produce the same result as the randomization contained within them is fundamentally different.</p>
</div>
<div id="distributions" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Distributions</h2>
<p>After reviewing the types and formats of the data inputs, we move on to some basic <strong>univariate</strong> (one variable at a time) analysis. We start by describing the distribution of values that each variable takes on. For nominal variables, this amounts to frequency tables and bar charts of how often each level of the variable appears in the data set.</p>
<p>We’ll begin by exploring one of our nominal features, <code>Heating_QC</code> which categorizes the quality and condition of a home’s heating system.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="eda.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames) <span class="sc">+</span></span>
<span id="cb15-2"><a href="eda.html#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Heating_QC))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:barchart"></span>
<img src="bookdownproj_files/figure-html/barchart-1.png" alt="Distribution of Nominal Variable Heating_QC" width="672" />
<p class="caption">
Figure 1.1: Distribution of Nominal Variable Heating_QC
</p>
</div>
<p>To summon the same information in tabular form, we can use the <code>count()</code> function to create a table:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="eda.html#cb16-1" aria-hidden="true" tabindex="-1"></a>ames <span class="sc">%&gt;%</span> </span>
<span id="cb16-2"><a href="eda.html#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(Heating_QC)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   Heating_QC     n
##   &lt;fct&gt;      &lt;int&gt;
## 1 Excellent   1495
## 2 Fair          92
## 3 Good         476
## 4 Poor           3
## 5 Typical      864</code></pre>
<p>You’ll notice that very few houses (3) have heating system in <code>Poor</code> condition, and the majority of houses have systems rated <code>Excellent</code>. <strong>It will likely make sense to combine the categories of <code>Fair</code> and <code>Poor</code> in our eventual analysis, a decision we will revisit later.</strong></p>
<p>Next we create a <strong>histogram</strong> for an interval attribute like <code>Sale_Price</code>:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="eda.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames) <span class="sc">+</span></span>
<span id="cb18-2"><a href="eda.html#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span> </span>
<span id="cb18-3"><a href="eda.html#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sales Price (Thousands $)&quot;</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<div class="figure" style="text-align: center"><span id="fig:histogram"></span>
<img src="bookdownproj_files/figure-html/histogram-1.png" alt="Distribution of Interval Variable Sale_Price" width="672" />
<p class="caption">
Figure 1.2: Distribution of Interval Variable Sale_Price
</p>
</div>
<p>From this initial inspection, we can conclude that most of the houses sell for less than $200,000 and there are a number of expensive anomalies. There are a number of more concrete ways that we can describe and quantify a statistical distribution; statistics that describe the <em>location, spread, and shape</em> of the data.</p>
<div id="location" class="section level3 unnumbered">
<h3>Location</h3>
<p>The <em>location</em> of a distribution refers to the x-axis of a histogram like that in Figure <a href="eda.html#fig:histogram">1.2</a>. Where is most of the data located? The sample <strong>mean</strong>, <strong>median</strong>, and <strong>mode</strong> are the most common statistics of location, but <strong>percentiles</strong> and the <strong>interquartile range</strong> can also be seen in this light.</p>
<p>We define each of these terms below for a variable <span class="math inline">\(\mathbf{x}\)</span> having n observations with values <span class="math inline">\(\{x_i\}_{i=1}^n\)</span>, sorted in order of magnitude such that <span class="math inline">\(x_1 \leq x_2 \leq \dots \leq x_n\)</span>:</p>
<ul>
<li>
Mean: The <strong>average</strong> of the observations, <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n x_i\)</span>
<li>
Median: The “middle value” of the data. Formally, when <span class="math inline">\(n\)</span> is odd, the median is the observation value, <span class="math inline">\(x_m = x_{\frac{(n+1)}{2}}\)</span> for which <span class="math inline">\(x_i &lt; x_m\)</span> for 50% of the observations (excluding <span class="math inline">\(x_m\)</span>). When <span class="math inline">\(n\)</span> is even, <span class="math inline">\(x_m\)</span> is the average of <span class="math inline">\(x_\frac{n}{2}\)</span> and <span class="math inline">\(x_{(\frac{n}{2}+1)}\)</span>. The median is also known as the <span class="math inline">\(2^{nd}\)</span> <strong>quartile</strong>.
<li>
Mode: The most commonly occurring value in the data. Most commonly used to describe nominal attributes.
<li>
Percentiles: The 99 intermediate values of the data which divide the observations into 100 equally-sized groups. The <span class="math inline">\(r^{th}\)</span> percentile of the data, <span class="math inline">\(P_r\)</span> is the number for which <span class="math inline">\(r\%\)</span> of the data is less than <span class="math inline">\(P_r\)</span>.
<li>
Quartiles: The quartiles of a variable are the <span class="math inline">\(25^{th}\)</span>, <span class="math inline">\(50^{th}\)</span>, and <span class="math inline">\(75^{th}\)</span> percentiles. They are denoted as <span class="math inline">\(Q_1\)</span> (<span class="math inline">\(1^{st}\)</span> quartile), <span class="math inline">\(Q_2\)</span> (<span class="math inline">\(2^{nd}\)</span> quartile = median), and <span class="math inline">\(Q_3\)</span> (<span class="math inline">\(3^{rd}\)</span> quartile) respectively.
</ul>
<div id="illustrative-example" class="section level5 unnumbered">
<h5>Illustrative Example</h5>
<p>Suppose the following table contains the heights of 10 students randomly sampled from NC State’s campus. Compute the mean, median, mode and quartiles of this variable.</p>
<table style="width:auto; margin-left: auto; margin-right: auto;" >
<tr>
<td style="text-align:center">
height
<td style="text-align:center">
60
<td style="text-align:center">
62
<td style="text-align:center">
63
<td style="text-align:center">
65
<td style="text-align:center">
67
<td style="text-align:center">
67
<td style="text-align:center">
67
<td style="text-align:center">
68
<td style="text-align:center">
68
<td style="text-align:center">
69
</table>
</div>
<div id="solution" class="section level5 unnumbered">
<h5>Solution:</h5>
<ul>
<li>
The mean is <code>(60+62+63+65+67+67+67+68+68+69)/10</code> = 65.6.
<li>
The median (second quartile) is <code>(67+67)/2</code> = 67.
<li>
The mode is 67.
<li>
The first quartile is <code>(62+63)/2</code> = 62.5
<li>
The third quartile is <code>(68+68)/2</code> = 68
</ul>
</div>
</div>
<div id="spread" class="section level3 unnumbered">
<h3>Spread</h3>
<p>Once we have an understanding of where the bulk of the data is located, we move on to describing the spread (the dispersion or variation) of the data. <strong>Range</strong>, <strong>interquartile range</strong>, <strong>variance</strong>, and <strong>standard deviation</strong> are all statistics that describe spread.</p>
<ul>
<li>
Range: The difference between the maximum and minimum data values.
<li>
Interquartile range (IQR): The difference between the $25^{th} and 75^{th} percentiles.
<li>
Sample variance: The sum of squared differences between each data point and the mean, divided by (n-1). <span class="math inline">\(\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar{x})^2\)</span>
<li>
<p>Standard deviation: The square root of the sample variance.</p>
<p>One should note that standard deviation is more frequently reported than variance because it shares the same units as the original data, and because of the guidance provided by the empirical rule. If we’re exploring something like <code>Sale_Price</code>, which has the unit “dollars”, then the variance would be measured in “square-dollars”, which hampers the intuition. Standard deviation, on the other hand, would share the unit “dollars”, aiding our fundamental understanding.</p>
<div id="illustrative-example-1" class="section level5 unnumbered">
<h5>Illustrative Example</h5>
<p>Let’s again use the table of heights, this time computing the range, IQR, sample variance and standard deviation.</p>
<table style="width:auto; margin-left: auto; margin-right: auto;" >
<tr>
<td style="text-align:center">
height
<td style="text-align:center">
60
<td style="text-align:center">
62
<td style="text-align:center">
63
<td style="text-align:center">
65
<td style="text-align:center">
67
<td style="text-align:center">
67
<td style="text-align:center">
67
<td style="text-align:center">
68
<td style="text-align:center">
68
<td style="text-align:center">
69
</table>
</div>
<div id="solution-1" class="section level5 unnumbered">
<h5>Solution:</h5>
<ul>
<code>(60+62+63+65+67+67+67+68+68+69)/10</code>
<li>
The range <code>69-60</code> = 9.
<li>
The IQR is <code>68 - 62.5</code> = 5.5.
<li>
The variance is <code>((60-65.6)^2+(62-65.6)^2+(63-65.6)^2+(65-65.6)^2+(67-65.6)^2+(67-65.6)^2+(67-65.6)^2+(68-65.6)^2+(68-65.6)^2+(69-65.6)^2)/9</code> = 8.933
<li>
The standard deviation is <code>sqrt(8.933)</code> = 2.989
</ul>
</div>
</div>
<div id="shape" class="section level3 unnumbered">
<h3>Shape</h3>
<p>The final description we will want to give to distributions regards their shape. Is the histogram <em>symmetric</em>? Is it <em>unimodal</em> (having a single large “heap” of data) or <em>multimodal</em> (having multiple heaps")? Does it have a longer tail on one side than the other (<em>skew</em>)? Is there a lot more or less data in the tails than you might expect?</p>
<p>We’ll formalize these ideas with some illustrations. A distribution is right (left) skewed if it has a longer tail on its right (left) side, as shown in Figure <a href="eda.html#fig:skewdiagram">1.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:skewdiagram"></span>
<img src="img/skewdiagrams.png" alt="Examples of Left-Skewed (Negative Skew) and Right-skewed (Positive Skew) distributions respectively" width="100%" />
<p class="caption">
Figure 1.3: Examples of Left-Skewed (Negative Skew) and Right-skewed (Positive Skew) distributions respectively
</p>
</div>
<p>A distribution is called <em>bimodal</em> if it has two “heaps”, as shown in Figure <a href="eda.html#fig:bimodal">1.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:bimodal"></span>
<img src="img/bimodal.png" alt="Example of a Bimodal Distribution" width="50%" />
<p class="caption">
Figure 1.4: Example of a Bimodal Distribution
</p>
</div>
</div>
<div id="summary-functions" class="section level3 unnumbered">
<h3>Summary Functions</h3>
<p>There are many ways to obtain all of the statistics described in the preceding sections, below we highlight 3:</p>
<ol>
<li>
<p>The <code>describe</code> function from the <code>Hmisc</code> package which can work on the entire dataset or a subset of columns.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="eda.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;Hmisc&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="eda.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb21-2"><a href="eda.html#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="eda.html#cb21-3" aria-hidden="true" tabindex="-1"></a>Hmisc<span class="sc">::</span><span class="fu">describe</span>(ames<span class="sc">$</span>Sale_Price)</span></code></pre></div>
<pre><code>## ames$Sale_Price 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##     2930        0     1032        1   180796    81960    87500   105450 
##      .25      .50      .75      .90      .95 
##   129500   160000   213500   281242   335000 
## 
## lowest :  12789  13100  34900  35000  35311, highest: 611657 615000 625000 745000 755000</code></pre>
<li>
<p>The tidyverse <code>summarise</code> function, in this case obtaining statistics for each <code>House_Style</code> separately.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="eda.html#cb23-1" aria-hidden="true" tabindex="-1"></a>ames <span class="sc">%&gt;%</span></span>
<span id="cb23-2"><a href="eda.html#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(<span class="st">`</span><span class="at">House_Style</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-3"><a href="eda.html#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean =</span> <span class="fu">mean</span>(Sale_Price), </span>
<span id="cb23-4"><a href="eda.html#cb23-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">sd =</span> <span class="fu">sd</span>(Sale_Price), </span>
<span id="cb23-5"><a href="eda.html#cb23-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">max =</span> <span class="fu">max</span>(Sale_Price), </span>
<span id="cb23-6"><a href="eda.html#cb23-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">min =</span> <span class="fu">min</span>(Sale_Price))</span></code></pre></div>
<pre><code>## # A tibble: 8 x 5
##   House_Style         mean      sd    max    min
##   &lt;fct&gt;              &lt;dbl&gt;   &lt;dbl&gt;  &lt;int&gt;  &lt;int&gt;
## 1 One_and_Half_Fin 137530.  47226. 410000  37900
## 2 One_and_Half_Unf 109663.  20570. 139400  64500
## 3 One_Story        178700.  81067. 615000  12789
## 4 SFoyer           143473.  31220. 224500  70000
## 5 SLvl             165527.  34348. 345000  91000
## 6 Two_and_Half_Fin 220000  118212. 475000 104000
## 7 Two_and_Half_Unf 177158.  76115. 415000  97500
## 8 Two_Story        206990.  85350. 755000  40000</code></pre>
<li>
<p>The base R <code>summary</code> function, which can work on the entire dataset or an individual variable</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="eda.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ames<span class="sc">$</span>Sale_Price)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   12789  129500  160000  180796  213500  755000</code></pre>
</div>
<div id="normal-distribution" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Normal Distribution</h3>
The normal distribution, also known as the Gaussian distribution, is one of the most fundamental concepts in statistics. It is one that arises naturally out of many applications and settings. The normal distribution has the following characteristics:
<ol>
<li>
Symmetric
<li>
Fully defined by mean and standard deviation (equivalently, variance)
<li>
Bell-shaped/Unimodal
<li>
Mean = Median = Mode
<li>
Assymptotic to the x-axis (theoretical bounds are <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>)
</ol>
<p>Much of the normal distributions utility can be summarized in the <strong>empirical rule</strong>, which states that:</p>
<ul>
<li>
68% of data in normal distribution lies within 1 standard deviation of the mean.
<li>
95% of data in normal distribution lies within 2 standard deviations of the mean.
<li>
99% of data in normal distribution lies within 3 standard deviations of the mean.
</ul>
<p>We can thus conclude that observations found outside of 3 standard deviations from the mean are quite rare, expected less than 1% of the time.</p>
<div id="skewness" class="section level4 unnumbered">
<h4>Skewness</h4>
<p>Skewness is a statistic that describes the symmetry (or lack thereof) of a distribution. A normal distribution is perfectly symmetric and has a skewness of 0. Distributions that are more right skewed will have positive values of skewness whereas distributions that are more left skewed will have negative values of skewness.</p>
</div>
<div id="kurtosis" class="section level4 unnumbered">
<h4>Kurtosis</h4>
<p>Kurtosis is a statistic that describes the <em>tailedness</em> of a distribution. The normal distribution has a kurtosis of 3. Distributions that are more tailed (leptokurtic or heavy-tailed) will have kurtosis values greater than 3 whereas distributions that are more less tailed (platykurtic or thin-tailed) will have values of kurtosis less than 3. For this reason, kurtosis is often reported in the form of <em>excess kurtosis</em> which is the raw kurtosis value minus 3. This is meant as a comparison to the normal distribution so that positive values indicate thicker tails and negative values indicate thinner tails than the normal.</p>
<p>In Figure <a href="eda.html#fig:kurtosis">1.5</a> below, we compare classical examples of leptokurtic and platykurtic distributions to a normal distribution with the same mean and variance.</p>
<div class="figure" style="text-align: center"><span id="fig:kurtosis"></span>
<img src="bookdownproj_files/figure-html/kurtosis-1.png" alt="The Laplace distribution (top left) is leptokurtic because it has more data in its tails than the normal distribution with the same mean and variance. The uniform distribution (top right) is platykurtic because it has less data in its tails than the normal distribution with the same mean and variance (it effectively has no tails)." width="672" />
<p class="caption">
Figure 1.5: The Laplace distribution (top left) is leptokurtic because it has more data in its tails than the normal distribution with the same mean and variance. The uniform distribution (top right) is platykurtic because it has less data in its tails than the normal distribution with the same mean and variance (it effectively has no tails).
</p>
</div>
</div>
</div>
<div id="graphical-displays-of-distributions" class="section level3 unnumbered">
<h3>Graphical Displays of Distributions</h3>
There are three types of plots for examining the distribution of your data values:
<ol>
<li>
Histograms
<li>
Normal Probability Plots (QQ-plots)
<li>
<p>Box Plots</p>
<p>Histograms were previously discussed, so we move on to probability plots (QQ-plots) and box plots.</p>
<div id="normal-probability-plots-qq-plots" class="section level4 unnumbered">
<h4>Normal probability plots (QQ Plots)</h4>
<p>A <strong>normal probability plot</strong> graphs the sorted data values against the values that one would expect if the same number of observations came from a theoretical normal distribution. The resulting image would look close to a straight line if the data was generated by a normal distribution. Strong deviations from a straight line indicate that the data distribution is not normal.</p>
<p>Figure <a href="eda.html#fig:qqplot">1.6</a> shows a QQ plot for <code>Sale_Price</code>, and we can conclude that the variable is not normally distributed.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="eda.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> ames, <span class="fu">aes</span>(<span class="at">sample =</span> Sale_Price<span class="sc">/</span><span class="dv">1000</span>)) <span class="sc">+</span></span>
<span id="cb27-2"><a href="eda.html#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb27-3"><a href="eda.html#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:qqplot"></span>
<img src="bookdownproj_files/figure-html/qqplot-1.png" alt="QQ-Plot: Quantiles of Sale_Price vs. quantiles of a theoretical normal distribution with same mean and standard deviation. Conclusion: Sale_Price is _not_ normally distributed." width="672" />
<p class="caption">
Figure 1.6: QQ-Plot: Quantiles of Sale_Price vs. quantiles of a theoretical normal distribution with same mean and standard deviation. Conclusion: Sale_Price is <em>not</em> normally distributed.
</p>
</div>
<p>There are two main patterns that we expect to find when examining QQ-plots. One is quadratic shape, as seen in Figure <a href="eda.html#fig:qqplot">1.6</a>. This pattern indicates a deviation from normality due to skewness to the data. The other is an S-shape (or cubic shape), as seen in Figure <a href="eda.html#fig:qqplotKurt">1.7</a>. This pattern indicates deviation from normality due to kurtosis.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="eda.html#cb28-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">j1 =</span> <span class="fu">rlaplace</span>(<span class="dv">10000</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb28-2"><a href="eda.html#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="eda.html#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> df, <span class="fu">aes</span>(<span class="at">sample=</span>j1)) <span class="sc">+</span></span>
<span id="cb28-4"><a href="eda.html#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb28-5"><a href="eda.html#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:qqplotKurt"></span>
<img src="bookdownproj_files/figure-html/qqplotKurt-1.png" alt="QQ-Plot: Quantiles of the Laplace distribution vs. quantiles of a theoretical normal distribution with same mean and standard deviation. Conclusion: Sale_Price is _not_ normally distributed." width="672" />
<p class="caption">
Figure 1.7: QQ-Plot: Quantiles of the Laplace distribution vs. quantiles of a theoretical normal distribution with same mean and standard deviation. Conclusion: Sale_Price is <em>not</em> normally distributed.
</p>
</div>
</div>
</div>
</div>
<div id="confidence-intervals" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Confidence Intervals</h2>
</div>
<div id="hypothesis-testing" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Hypothesis Testing</h2>
</div>
<div id="two-sample-t-tests" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Two-Sample t-tests</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="slr.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/IAA-Faculty/statistical_foundations.git/edit/master/01-introduction_statistics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/IAA-Faculty/statistical_foundations.git/blob/master/01-introduction_statistics.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"toc": null
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
